
R Under development (unstable) (2019-03-18 r76245) -- "Unsuffered Consequences"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lubridate)

Attaching package: ‘lubridate’

The following object is masked from ‘package:base’:

    date

> library(caret)
Loading required package: lattice
Loading required package: ggplot2
Registered S3 methods overwritten by 'ggplot2':
  method         from 
  [.quosures     rlang
  c.quosures     rlang
  print.quosures rlang
> library(tidymodels)
Registered S3 method overwritten by 'xts':
  method     from
  as.zoo.xts zoo 
── Attaching packages ────────────────────────────────────── tidymodels 0.0.2 ──
✔ broom     0.5.1       ✔ purrr     0.3.2  
✔ dials     0.0.2       ✔ recipes   0.1.5  
✔ dplyr     0.8.0.1     ✔ rsample   0.0.4  
✔ infer     0.4.0       ✔ tibble    2.1.1  
✔ parsnip   0.0.2       ✔ yardstick 0.0.2  
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard()       masks scales::discard()
✖ dplyr::filter()        masks stats::filter()
✖ dplyr::lag()           masks stats::lag()
✖ purrr::lift()          masks caret::lift()
✖ yardstick::precision() masks caret::precision()
✖ yardstick::recall()    masks caret::recall()
✖ recipes::step()        masks stats::step()
> library(tidytext)
> library(SnowballC)
> library(textfeatures)
> library(sessioninfo)
> 
> # ------------------------------------------------------------------------------
> 
> data(stop_words)
> 
> stop_words <- stop_words %>% filter(lexicon == "SMART")
> 
> # ------------------------------------------------------------------------------
> ## Some levels of predictors have spaces or symbols; fix these
> ## and replace "" with "missing"
> 
> fix_levels <- function(x, add_missing = "missing") {
+   x <- gsub("&rsquo;", "", x)
+   x <- gsub("[[:space:]]", "_", x)
+   x <- gsub("[[:punct:]]", "_", x)
+   x <- gsub("__", "_", x, perl = TRUE)
+   x <- gsub("__", "_", x, perl = TRUE)
+   x <- gsub("__", "_", x, perl = TRUE)
+   if (!is.null(add_missing))
+     x[x == ""] <- add_missing
+   resort_lvl(x)
+ }
> 
> # ------------------------------------------------------------------------------
> ## resort categorical predictors so that "missing" is the first level
> 
> resort_lvl <- function(x) {
+   x <- as.character(x)
+   miss_val <- grep("missing$", unique(x), value = TRUE)
+   if(length(miss_val) > 0)
+     lv <- c(miss_val, sort(unique(x[x != miss_val])))
+   else
+     lv <- sort(unique(x))
+   factor(x, levels = lv)
+ }
> 
> # ------------------------------------------------------------------------------
> ## Unpackage the data and read in. A compressed version of the csv
> ## file is at https://github.com/rudeboybert/JSE_OkCupid
> 
> raw <- 
+   read.csv("profiles.csv", stringsAsFactors = FALSE) %>% 
+   dplyr::select(-sex, -body_type, -orientation)
> 
> # ------------------------------------------------------------------------------
> ## Compute the number of days since last online
> 
> tmp_last <- ymd(substring(raw$last_online, 1, 10))
> tmp_last <- difftime(max(tmp_last), tmp_last, units = "days")
> raw$last_online <- as.numeric(tmp_last)
> 
> # ------------------------------------------------------------------------------
> ## encode the "easy" categorical predictors
> 
> raw$drinks <- fix_levels(raw$drinks, "drinks_missing")
> raw$drugs <- fix_levels(raw$drugs, "drugs_missing")
> raw$education <- fix_levels(raw$education, "ed_missing")
> raw$diet <- fix_levels(raw$diet,"diet_missing")
> raw$job <- fix_levels(raw$job, "missing")
> raw$offspring <- fix_levels(raw$offspring, "kids_missing")
> raw$pets <- fix_levels(raw$pets, "pets_missing")
> raw$smokes <- fix_levels(raw$smokes, "smokes_missing")
> raw$status <- fix_levels(raw$status)
> 
> # ------------------------------------------------------------------------------
> ## Income is basically encoded categorical so we will make it a factor
> 
> test <- ifelse(raw$income == -1, NA, raw$income)
> test <- factor(paste0("inc", test), levels = c("missing", paste0("inc", sort(unique(test)))))
> test[is.na(test)] <- "missing"
> raw$income <- test
> 
> # ------------------------------------------------------------------------------
> ## Split their location into city and state. There are some R functions
> ## (ahem, randomForest) that can only handle predictors with <=52
> ## levels so we take the long tail of the distribution and truncate
> ## some cities to "other"
> 
> tmp_where <- strsplit(raw$location, split = ", ")
> where_state <- 
+   map_chr(tmp_where, function(x) if(length(x) == 2) x[2] else "missing")
> where_town <- 
+   map_chr(tmp_where, function(x) if(length(x) == 2) x[1] else "missing")
> 
> town_tab <- sort(-table(where_town))
> where_town[!(where_town %in% names(town_tab)[1:50])] <- "other"
> 
> raw$where_state <- factor(gsub(" ", "_", where_state))
> raw$where_town <- factor(gsub(" ", "_", where_town))
> raw$location <- NULL
> 
> # ------------------------------------------------------------------------------
> ## Some predictors have values and modifiers that describe how
> ## serious they are about their choice. We will create predictors
> ## for both characteristics of their answer
> 
> ## for religion, split religion and modifier
> tmp_relig_split <- strsplit(raw$religion, split = " ")
> tmp_relig <- unlist(lapply(tmp_relig_split, function(x) x[1]))
> tmp_relig[tmp_relig == ""] <- "religion_missing"
> tmp_relig[is.na(tmp_relig)] <- "religion_missing"
> raw$religion <- resort_lvl(tmp_relig)
> 
> rel_mod <- function(x) {
+   if (length(x) > 1) {
+     paste(x[-1], collapse = "_")
+   } else {
+     "religion_mod_missing"
+   }
+ }
> 
> raw$religion_modifer <- map_chr(tmp_relig_split, rel_mod)
> raw$religion_modifer <- resort_lvl(raw$religion_modifer)
> 
> # ------------------------------------------------------------------------------
> ## Same for sign
> 
> raw$sign <- gsub("&rsquo;", "", raw$sign)
> tmp_sign_split <- strsplit(raw$sign, split = " ")
> tmp_sign <- map_chr(tmp_sign_split, function(x) x[1])
> sign_lvl <- sort(unique(tmp_sign))
> tmp_sign[tmp_sign == ""] <- "sign_missing"
> tmp_sign[is.na(tmp_sign)] <- "sign_missing"
> raw$sign <- resort_lvl(tmp_sign)
> 
> sign_mod <- function(x) {
+   if (length(x) > 1) {
+     paste(x[-1], collapse = "_")
+   } else {
+     "sign_mod_missing"
+   }
+ }
> raw$sign_modifer <- map_chr(tmp_sign_split, sign_mod)
> raw$sign_modifer <- resort_lvl(raw$sign_modifer)
> 
> # ------------------------------------------------------------------------------
> ## They are allowed to list multiple languages so we will pre-split
> ## these into dummy variables since they might have multiple choices.
> ## Also, "c++" and "lisp" !
> 
> tmp_speaks <- gsub("(", "", raw$speaks, fixed = TRUE)
> tmp_speaks <- gsub(")", "", tmp_speaks, fixed = TRUE)
> tmp_speaks <- gsub("c++", "cpp", tmp_speaks, fixed = TRUE)
> tmp_speaks_split <- strsplit(tmp_speaks, split = ",")
> tmp_speaks_split <- lapply(tmp_speaks_split, function(x) gsub("^ ", "", x))
> tmp_speaks_split <- lapply(tmp_speaks_split, function(x) gsub(" ", "_", x))
> speaks_values <- sort(unique(unlist(tmp_speaks_split)))
> # just keep prog langs
> speaks_values <- grep("(cpp)|(lisp)", speaks_values, value = TRUE)
> for (i in speaks_values) 
+   raw[, i] <- ifelse(
+     map_chr(tmp_speaks_split, function(x, sp) any(x == sp), sp = i), 
+     1, 0
+   )
> raw$speaks <- NULL
> 
> # ------------------------------------------------------------------------------
> ## Similaly, ethnicity is pre-split into dummy variables
> 
> tmp_eth <- gsub(", ", ",", raw$ethnicity)
> tmp_eth <- gsub("/ ", "", tmp_eth)
> tmp_eth <- gsub(" ", "_", tmp_eth)
> tmp_eth_split <- strsplit(tmp_eth, split = ",")
> eth_lvl <- sort(unique(unlist(tmp_eth_split)))
> for (i in eth_lvl) 
+   raw[, i] <- ifelse(
+     map_chr(tmp_eth_split, function(x, eth) any(x == eth), eth = i), 
+     1, 0
+   )
> raw$ethnicity <- NULL
> 
> # ------------------------------------------------------------------------------
> ## Get the essay data
> 
> is_essay <- grepl("^essay", names(raw))
> essay_names <- names(raw)[is_essay]
> 
> ess <- apply(raw[, essay_names],  1, paste, collapse = " ")
> ess <- gsub("\n", " ", ess, fixed = TRUE)
> 
> raw$essay_length <- log10(nchar(ess) - 8)
> 
> raw <- raw[, !is_essay]
> raw$essays <- ess
> 
> # ------------------------------------------------------------------------------
> ## There are very few missing values for continuous fields so 
> ## remove them and convert the job field to the outcome. 
> 
> okc <- raw[complete.cases(raw),]
> 
> okc$Class <- factor(ifelse(grepl("(computer)|(science)", okc$job), "stem", "other"),
+                     levels = c("stem", "other"))
> 
> 
> okc <- okc[okc$job != "missing",]
> okc$job <- NULL
> okc$profile <- 1:nrow(okc)
> 
> basic_features <-
+   textfeatures(
+     okc$essays,
+     normalize = FALSE,
+     export = FALSE,
+     word_dims = 0,
+     threads = 4
+   ) %>%
+   dplyr::select(-n_caps, -id, -n_nonasciis, -n_capsp, -n_chars) %>%
+   mutate(profile = okc$profile)
> 
> 
> # ------------------------------------------------------------------------------
> ## Split the data
> 
> set.seed(6830)
> in_test <- createDataPartition(okc$Class, p = .25, list = FALSE)
> 
> okc_test  <- okc[ in_test, ]
> okc_train <- okc[-in_test, ]
> 
> basic_features_train  <- basic_features[-in_test, ]
> basic_features_train$profile <- okc_train$profile
> basic_features_test   <- basic_features[ in_test, ]
> basic_features_test$profile <- okc_test$profile
> 
> set.seed(7520)
> okc_down <- downSample(x = okc_train[, names(okc_train) != "Class"],
+                        y = okc_train$Class)
> 
> basic_features_down <-
+   textfeatures(
+     okc_down$essays,
+     normalize = FALSE,
+     export = FALSE,
+     word_dims = 0,
+     threads = 4
+   ) %>%
+   dplyr::select(-n_caps, -id, -n_nonasciis, -n_capsp) %>%
+   mutate(profile = okc_down$profile)
> 
> # ------------------------------------------------------------------------------
> ## Create the smaller downsampled set of data for the keyword analysis
> 
> set.seed(4808)
> sampled_rows <- 
+   createDataPartition(okc_down$Class, p = 10000/nrow(okc_down), list = FALSE)
> 
> okc_sampled <- okc_down[sampled_rows,]
> 
> sampled_summaries <- okc_down[sampled_rows, c("Class", "essay_length")]
> 
> essays <- okc_down[sampled_rows, c("Class", "essays", "profile")]
> char_dist <- nchar(essays$essays)
> no_essays <- sum(char_dist == 9)
> char_dist <- char_dist[char_dist > 9] - 9
> 
> has_link <- ifelse(grepl("(href)|(www\\.[[:alpha:]])", essays$essays), 1, 0)
> 
> essays <- 
+   essays %>%
+   mutate(essays = gsub("\n", " ", essays, fixed = TRUE),
+          essays = gsub("<br />", " ", essays),
+          essays = gsub("<.*?>", " ", essays),# find a way to keep hrefs?
+          essays = gsub("/", " ", essays),
+          essays = gsub("[[:punct:]]", " ", essays),
+          essays = gsub("[[:digit:]]", " ", essays)) 
> 
> # ------------------------------------------------------------------------------
> 
> link_tab <- 
+   table(
+     has_link, 
+     okc_sampled$Class
+     )
> 
> # ------------------------------------------------------------------------------
> ## Get the individual words and stem
> 
> words <- 
+   essays %>%
+   unnest_tokens(word, essays) %>%
+   ## remove repeated characters like 'aaaaaaaa'
+   dplyr::filter(!grepl("\\b(\\S+?)\\1\\S*\\b", word, perl = TRUE)) 
> 
> all_words_n <- length(unique(words$word))
> 
> stopped_words <- 
+   words %>%
+   anti_join(stop_words, by = "word")
> 
> stopped_words_n <- length(unique(stopped_words$word))
> 
> stemmed_words <- 
+   stopped_words %>%
+   ## stem the words
+   mutate(word = wordStem(word))
> 
> stemmed_words_n <- length(unique(stemmed_words$word))
> 
> # ------------------------------------------------------------------------------
> ## Odds-ratio analysis
> 
> calc_or <- function(x) {
+   if (nrow(x) != 2) 
+     return(data.frame(or = NA, 
+                       pvalue = NA,
+                       stem = NA,
+                       other = NA))
+   dat <- x[, c("yes", "no")]
+   mat <- as.matrix(dat)
+   tab <- as.table(mat)
+   rownames(tab) <- x$Class
+   res <- fisher.test(tab)
+   data.frame(or = unname(res$estimate), 
+              pvalue = res$p.value,
+              stem = tab["stem", "yes"]/sum(tab["stem",]),
+              other = tab["other", "yes"]/sum(tab["other",]),
+              events = sum(tab[, "yes"]))
+ }
> 
> total_words_by_class <- 
+   words %>%
+   group_by(Class) %>%
+   summarize(total = length(unique(profile)))
> 
> word_counts <- 
+   words %>%
+   group_by(Class, word) %>%
+   summarize(yes = length(unique(profile))) %>%
+   full_join(total_words_by_class) %>%
+   mutate(no = total - yes)
Joining, by = "Class"
> 
> low_events <- 
+   word_counts %>%
+   group_by(word) %>%
+   summarize(events = sum(yes)) %>%
+   dplyr::filter(events < 50) %>%
+   dplyr::select(-events)
> 
> keyword_results <- 
+   word_counts %>%
+   anti_join(low_events) %>%
+   group_by(word) %>%
+   do(calc_or(.)) 
Joining, by = "word"
> 
> keyword_results$FDR <- p.adjust(keyword_results$pvalue)
> 
> # ggplot(keyword_results, aes(x = or, y = -log10(FDR))) + 
> #   geom_point(alpha = .2, aes(size = sqrt(events))) + 
> #   scale_x_log10()
> 
> hits <- 
+   keyword_results %>% 
+   filter(-log10(FDR) > 5 & (or > 2 | or < 1/2)) %>%
+   arrange(FDR)
> 
> keywords <- hits$word
> 
> # ------------------------------------------------------------------------------
> ## Binary keyword indicators (for word embedding model)
> 
> binary_key <- recipe(~ essays + profile, data = okc_train %>% head())
> 
> for (i in keywords) 
+   binary_key <- 
+   binary_key %>%
+   step_regex(essays, pattern = paste0(" ", i), result = i)
> 
> binary_key <- 
+   binary_key %>%
+   step_rm(essays)
> 
> binary_key <- prep(binary_key, training = okc_train)
> okc_train_binary <- juice(binary_key) 
> okc_test_binary <- bake(binary_key, okc_test) 
> 
> # ------------------------------------------------------------------------------
> ## Counts of keyword occurances
> 
> count_key <- recipe(~ essays + profile, data = okc_train %>% head())
> 
> for (i in keywords) 
+   count_key <- 
+   count_key %>%
+   step_count(essays, pattern = paste0(" ", i), result = paste0("n_", i))
> 
> count_key <- 
+   count_key %>%
+   step_rm(essays) %>%
+   step_corr(matches("^n_"), threshold = .90)
> 
> count_key <- prep(count_key, training = okc_train)
> okc_train_count <- juice(count_key)
> okc_test_count <- bake(count_key, okc_test)
> okc_down_count <- 
+   okc_train_count %>%
+   dplyr::filter(profile %in% okc_down$profile)
> 
> # ------------------------------------------------------------------------------
> ## Save the various objects
> 
> save(no_essays, char_dist, hits, link_tab,
+      all_words_n, stopped_words_n, stemmed_words_n,
+      sampled_summaries,
+      keyword_results, keywords,
+      file = "okc_info.RData")
> 
> save(okc_train_binary, okc_test_binary, file = "okc_binary.RData")
> save(okc_train_count, okc_test_count, file = "okc_counts.RData")
> save(basic_features_train, basic_features_test, file = "okc_features.RData")
> 
> okc_test$essays <- NULL
> okc_train$essays <- NULL
> okc_down$essays <- NULL
> 
> save(okc_test, okc_train, okc_down, okc_sampled, file = "okc.RData")
> save(ess, file = "essays.RData")
> save(speaks_values, eth_lvl, file = "okc_other.RData")
> 
> # ------------------------------------------------------------------------------
> ##
> 
> print(session_info())
─ Session info ───────────────────────────────────────────────────────────────
 setting  value                                             
 version  R Under development (unstable) (2019-03-18 r76245)
 os       macOS High Sierra 10.13.6                         
 system   x86_64, darwin15.6.0                              
 ui       X11                                               
 language (EN)                                              
 collate  en_US.UTF-8                                       
 ctype    en_US.UTF-8                                       
 tz       America/New_York                                  
 date     2019-04-04                                        

─ Packages ───────────────────────────────────────────────────────────────────
 package       * version    date       lib source                            
 assertthat      0.2.1      2019-03-21 [1] CRAN (R 3.6.0)                    
 backports       1.1.3      2018-12-14 [1] CRAN (R 3.6.0)                    
 base64enc       0.1-3      2015-07-28 [1] CRAN (R 3.6.0)                    
 bayesplot       1.6.0      2018-08-02 [1] CRAN (R 3.6.0)                    
 broom         * 0.5.1      2018-12-05 [1] CRAN (R 3.6.0)                    
 callr           3.2.0      2019-03-15 [1] CRAN (R 3.6.0)                    
 caret         * 6.0-82     2019-03-26 [1] CRAN (R 3.6.0)                    
 class           7.3-15     2019-01-01 [1] CRAN (R 3.6.0)                    
 cli             1.1.0      2019-03-19 [1] CRAN (R 3.6.0)                    
 codetools       0.2-16     2018-12-24 [1] CRAN (R 3.6.0)                    
 colorspace      1.4-1      2019-03-18 [1] CRAN (R 3.6.0)                    
 colourpicker    1.0        2017-09-27 [1] CRAN (R 3.6.0)                    
 crayon          1.3.4      2017-09-16 [1] CRAN (R 3.6.0)                    
 crosstalk       1.0.0      2016-12-21 [1] CRAN (R 3.6.0)                    
 data.table      1.12.0     2019-01-13 [1] CRAN (R 3.6.0)                    
 dials         * 0.0.2      2018-12-09 [1] CRAN (R 3.6.0)                    
 digest          0.6.18     2018-10-10 [1] CRAN (R 3.6.0)                    
 dplyr         * 0.8.0.1    2019-02-15 [1] CRAN (R 3.6.0)                    
 DT              0.5        2018-11-05 [1] CRAN (R 3.6.0)                    
 dygraphs        1.1.1.6    2018-07-11 [1] CRAN (R 3.6.0)                    
 foreach         1.4.4      2017-12-12 [1] CRAN (R 3.6.0)                    
 generics        0.0.2      2018-11-29 [1] CRAN (R 3.6.0)                    
 ggplot2       * 3.1.0      2018-10-25 [1] CRAN (R 3.6.0)                    
 ggridges        0.5.1      2018-09-27 [1] CRAN (R 3.6.0)                    
 glue            1.3.1      2019-03-12 [1] CRAN (R 3.6.0)                    
 gower           0.2.0      2019-03-07 [1] CRAN (R 3.6.0)                    
 gridExtra       2.3        2017-09-09 [1] CRAN (R 3.6.0)                    
 gtable          0.2.0      2016-02-26 [1] CRAN (R 3.6.0)                    
 gtools          3.8.1      2018-06-26 [1] CRAN (R 3.6.0)                    
 htmltools       0.3.6      2017-04-28 [1] CRAN (R 3.6.0)                    
 htmlwidgets     1.3        2018-09-30 [1] CRAN (R 3.6.0)                    
 httpuv          1.4.5.1    2018-12-18 [1] CRAN (R 3.6.0)                    
 igraph          1.2.4      2019-02-13 [1] CRAN (R 3.6.0)                    
 infer         * 0.4.0      2018-11-15 [1] CRAN (R 3.6.0)                    
 inline          0.3.15     2018-05-18 [1] CRAN (R 3.6.0)                    
 ipred           0.9-8      2018-11-05 [1] CRAN (R 3.6.0)                    
 iterators       1.0.10     2018-07-13 [1] CRAN (R 3.6.0)                    
 janeaustenr     0.1.5      2017-06-10 [1] CRAN (R 3.6.0)                    
 knitr           1.22       2019-03-08 [1] CRAN (R 3.6.0)                    
 later           0.8.0      2019-02-11 [1] CRAN (R 3.6.0)                    
 lattice       * 0.20-38    2018-11-04 [1] CRAN (R 3.6.0)                    
 lava            1.6.5      2019-02-12 [1] CRAN (R 3.6.0)                    
 lazyeval        0.2.2      2019-03-15 [1] CRAN (R 3.6.0)                    
 lme4            1.1-20     2019-02-04 [1] CRAN (R 3.6.0)                    
 loo             2.0.0      2018-04-11 [1] CRAN (R 3.6.0)                    
 lubridate     * 1.7.4      2018-04-11 [1] CRAN (R 3.5.0)                    
 magrittr        1.5        2014-11-22 [1] CRAN (R 3.6.0)                    
 markdown        0.9        2018-12-07 [1] CRAN (R 3.6.0)                    
 MASS            7.3-51.4   2019-03-31 [1] CRAN (R 3.6.0)                    
 Matrix          1.2-16     2019-03-08 [1] CRAN (R 3.6.0)                    
 matrixStats     0.54.0     2018-07-23 [1] CRAN (R 3.6.0)                    
 mime            0.6        2018-10-05 [1] CRAN (R 3.6.0)                    
 miniUI          0.1.1.1    2018-05-18 [1] CRAN (R 3.6.0)                    
 minqa           1.2.4      2014-10-09 [1] CRAN (R 3.6.0)                    
 ModelMetrics    1.2.2      2018-11-03 [1] CRAN (R 3.6.0)                    
 munsell         0.5.0      2018-06-12 [1] CRAN (R 3.6.0)                    
 nlme            3.1-137    2018-04-07 [1] CRAN (R 3.6.0)                    
 nloptr          1.2.1      2018-10-03 [1] CRAN (R 3.6.0)                    
 nnet            7.3-12     2016-02-02 [1] CRAN (R 3.6.0)                    
 parsnip       * 0.0.2      2019-03-22 [1] CRAN (R 3.6.0)                    
 pillar          1.3.1      2018-12-15 [1] CRAN (R 3.6.0)                    
 pkgbuild        1.0.3      2019-03-20 [1] CRAN (R 3.6.0)                    
 pkgconfig       2.0.2      2018-08-16 [1] CRAN (R 3.6.0)                    
 plyr            1.8.4      2016-06-08 [1] CRAN (R 3.6.0)                    
 prettyunits     1.0.2      2015-07-13 [1] CRAN (R 3.6.0)                    
 pROC            1.14.0     2019-03-12 [1] CRAN (R 3.6.0)                    
 processx        3.3.0      2019-03-10 [1] CRAN (R 3.6.0)                    
 prodlim         2018.04.18 2018-04-18 [1] CRAN (R 3.6.0)                    
 promises        1.0.1      2018-04-13 [1] CRAN (R 3.6.0)                    
 ps              1.3.0      2018-12-21 [1] CRAN (R 3.6.0)                    
 purrr         * 0.3.2      2019-03-15 [1] CRAN (R 3.6.0)                    
 R6              2.4.0      2019-02-14 [1] CRAN (R 3.6.0)                    
 Rcpp            1.0.1      2019-03-17 [1] CRAN (R 3.6.0)                    
 recipes       * 0.1.5      2019-03-21 [1] CRAN (R 3.6.0)                    
 reshape2        1.4.3      2017-12-11 [1] CRAN (R 3.6.0)                    
 rlang           0.3.3      2019-03-29 [1] CRAN (R 3.6.0)                    
 rpart           4.1-13     2018-02-23 [1] CRAN (R 3.6.0)                    
 rsample       * 0.0.4      2019-01-07 [1] CRAN (R 3.6.0)                    
 rsconnect       0.8.13     2019-01-10 [1] CRAN (R 3.6.0)                    
 rstan           2.18.2     2018-11-07 [1] CRAN (R 3.6.0)                    
 rstanarm        2.18.2     2018-11-10 [1] CRAN (R 3.6.0)                    
 rstantools      1.5.1      2018-08-22 [1] CRAN (R 3.6.0)                    
 rstudioapi      0.10       2019-03-19 [1] CRAN (R 3.6.0)                    
 scales        * 1.0.0      2018-08-09 [1] CRAN (R 3.6.0)                    
 sessioninfo   * 1.1.1.9000 2019-03-26 [1] Github (r-lib/sessioninfo@dfb3ea8)
 shiny           1.2.0      2018-11-02 [1] CRAN (R 3.6.0)                    
 shinyjs         1.0        2018-01-08 [1] CRAN (R 3.6.0)                    
 shinystan       2.5.0      2018-05-01 [1] CRAN (R 3.6.0)                    
 shinythemes     1.1.2      2018-11-06 [1] CRAN (R 3.6.0)                    
 SnowballC     * 0.6.0      2019-01-15 [1] CRAN (R 3.6.0)                    
 StanHeaders     2.18.1     2019-01-28 [1] CRAN (R 3.6.0)                    
 stringi         1.4.3      2019-03-12 [1] CRAN (R 3.6.0)                    
 stringr         1.4.0      2019-02-10 [1] CRAN (R 3.6.0)                    
 survival        2.43-3     2018-11-26 [1] CRAN (R 3.6.0)                    
 syuzhet         1.0.4      2017-12-14 [1] CRAN (R 3.6.0)                    
 textfeatures  * 0.3.0      2018-11-29 [1] CRAN (R 3.6.0)                    
 tfse            0.5.0      2019-02-11 [1] CRAN (R 3.6.0)                    
 threejs         0.3.1      2017-08-13 [1] CRAN (R 3.6.0)                    
 tibble        * 2.1.1      2019-03-16 [1] CRAN (R 3.6.0)                    
 tidymodels    * 0.0.2      2018-11-27 [1] CRAN (R 3.6.0)                    
 tidyposterior   0.0.2      2018-11-15 [1] CRAN (R 3.6.0)                    
 tidypredict     0.3.0      2019-03-30 [1] local                             
 tidyr         * 0.8.3      2019-03-01 [1] CRAN (R 3.6.0)                    
 tidyselect      0.2.5      2018-10-11 [1] CRAN (R 3.6.0)                    
 tidytext      * 0.2.0      2018-10-17 [1] CRAN (R 3.6.0)                    
 timeDate        3043.102   2018-02-21 [1] CRAN (R 3.6.0)                    
 tokenizers      0.2.1      2018-03-29 [1] CRAN (R 3.6.0)                    
 withr           2.1.2      2018-03-15 [1] CRAN (R 3.6.0)                    
 xfun            0.5        2019-02-20 [1] CRAN (R 3.6.0)                    
 xtable          1.8-3      2018-08-29 [1] CRAN (R 3.6.0)                    
 xts             0.11-2     2018-11-05 [1] CRAN (R 3.6.0)                    
 yardstick     * 0.0.2      2018-11-05 [1] CRAN (R 3.6.0)                    
 zoo             1.8-5      2019-03-21 [1] CRAN (R 3.6.0)                    

[1] /Library/Frameworks/R.framework/Versions/3.6/Resources/library
> 
> if (!interactive())
+   q("no")
> proc.time()
   user  system elapsed 
400.946  10.384 411.346 
