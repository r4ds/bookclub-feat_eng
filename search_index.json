[["index.html", "Feature Engineering and Selection Book Club Welcome", " Feature Engineering and Selection Book Club The R4DS Online Learning Community 2022-09-24 Welcome Welcome to the bookclub! This is a companion for the book Feature Engineering and Selection: A Practical Approach for Predictive Models by Max Kuhn and Kjell Johnson (Chapman and Hall/CRC, copyright August 2, 2019, 9781138079229). This companion is available at r4ds.io/feat_eng. This website is being developed by the R4DS Online Learning Community. Follow along, and join the community to participate. This companion follows the R4DS Online Learning Community Code of Conduct. "],["book-club-meetings.html", "Book club meetings", " Book club meetings Each week, a volunteer will present a chapter from the book (or part of a chapter). This is the best way to learn the material. Presentations will usually consist of a review of the material, a discussion, and/or a demonstration of the principles presented in that chapter. More information about how to present is available in the github repo. Presentations will be recorded, and will be available on the R4DS Online Learning Community YouTube Channel. "],["pace.html", "Pace", " Pace We’ll try to cover 1 chapter/week, but… …It’s ok to split chapters when they feel like too much. We will try to meet every week, but will likely take some breaks for holidays, etc. "],["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction Learning objectives: Recognize the structure of the book Establish base lines for good practice Define feature engineering "],["structure-of-the-book.html", "1.1 Structure of the book", " 1.1 Structure of the book The book is divided into two main parts: Feature engineering (techniques for augmenting predictors - chapters 2-9) Predicting risk of Ischemic Review of the PMP (predictive modeling process) Exploratory visualization Encoding categorical predictors Engineering numeric predictors Detecting interaction effects Handling missing data Working with profile data (time series analysis) Feature selection (methods for filtering the enhanced predictors - chapters 10-12) Overview Greedy search methods (simple filters and eliminations) Golbal search methods (predictor space investigations) "],["good-practice-guidelines.html", "1.2 Good Practice guidelines", " 1.2 Good Practice guidelines There are some vital steps to take to modeling: knowledge of the process to model collect appropriate data understand variation in the response select relevant predictors utilize a range of models All of these are not enough when model lacks on performance. The answer might be the in the way the predictors are presented to the model. 1.2.1 What is feature engineering “…best re-representation of the predictors to improve model performance.” (ct. Preface) What are the possible ways to acheive a better performance? transform the predictors with special functions (log/exp) add an interaction term (prod/ratio) add a functional transformation (splines/poly) add a re-representation of the predictors (mean/med/standardz) imputing missing values (knn/bagging) Disclaimer: Risk of Overfitting! 1.2.2 Nature of modeling The estimation of uncertainty/noise is another very important step to take. “If a model is only 50% accurate should it be used to make inferences or predictions?” The trade-off between accuracy and interpretability is important, a neural network model might be less explicable but can provide a higher level of accuracy. Feature engineering is a matter of choice in finding the most suitable variable transformation for the best performance. More considerations about bad model reactions to: multicollinarity or correlation between predictors missing values irrelevant predictors "],["a-model-with-two-predictors.html", "1.3 A model with two predictors", " 1.3 A model with two predictors data(segmentationData) This example uses segmentationData. Data originates from an experiment from Hill et al. (2007), a study on “Impact of Image Segmentation on High-Content Screening Data Quality for SK-BR-3 Cells.” BMC Bioinformatics. The data set includes a Case vector containing Train and Test variables, with a total of 61 different vectors, about cellular structures and morphology. Selected for this first example are two predictors: EqSphereAreaCh1 and PerimCh1. The objective is to predict shape parameters of poorly-segmented (PS) and well-segmented (WS) cells from the Class variable. This is the full list of variables in the set. ## [1] &quot;Cell&quot; &quot;Case&quot; ## [3] &quot;Class&quot; &quot;AngleCh1&quot; ## [5] &quot;AreaCh1&quot; &quot;AvgIntenCh1&quot; ## [7] &quot;AvgIntenCh2&quot; &quot;AvgIntenCh3&quot; ## [9] &quot;AvgIntenCh4&quot; &quot;ConvexHullAreaRatioCh1&quot; ## [11] &quot;ConvexHullPerimRatioCh1&quot; &quot;DiffIntenDensityCh1&quot; ## [13] &quot;DiffIntenDensityCh3&quot; &quot;DiffIntenDensityCh4&quot; ## [15] &quot;EntropyIntenCh1&quot; &quot;EntropyIntenCh3&quot; ## [17] &quot;EntropyIntenCh4&quot; &quot;EqCircDiamCh1&quot; ## [19] &quot;EqEllipseLWRCh1&quot; &quot;EqEllipseOblateVolCh1&quot; ## [21] &quot;EqEllipseProlateVolCh1&quot; &quot;EqSphereAreaCh1&quot; ## [23] &quot;EqSphereVolCh1&quot; &quot;FiberAlign2Ch3&quot; ## [25] &quot;FiberAlign2Ch4&quot; &quot;FiberLengthCh1&quot; ## [27] &quot;FiberWidthCh1&quot; &quot;IntenCoocASMCh3&quot; ## [29] &quot;IntenCoocASMCh4&quot; &quot;IntenCoocContrastCh3&quot; ## [31] &quot;IntenCoocContrastCh4&quot; &quot;IntenCoocEntropyCh3&quot; ## [33] &quot;IntenCoocEntropyCh4&quot; &quot;IntenCoocMaxCh3&quot; ## [35] &quot;IntenCoocMaxCh4&quot; &quot;KurtIntenCh1&quot; ## [37] &quot;KurtIntenCh3&quot; &quot;KurtIntenCh4&quot; ## [39] &quot;LengthCh1&quot; &quot;NeighborAvgDistCh1&quot; ## [41] &quot;NeighborMinDistCh1&quot; &quot;NeighborVarDistCh1&quot; ## [43] &quot;PerimCh1&quot; &quot;ShapeBFRCh1&quot; ## [45] &quot;ShapeLWRCh1&quot; &quot;ShapeP2ACh1&quot; ## [47] &quot;SkewIntenCh1&quot; &quot;SkewIntenCh3&quot; ## [49] &quot;SkewIntenCh4&quot; &quot;SpotFiberCountCh3&quot; ## [51] &quot;SpotFiberCountCh4&quot; &quot;TotalIntenCh1&quot; ## [53] &quot;TotalIntenCh2&quot; &quot;TotalIntenCh3&quot; ## [55] &quot;TotalIntenCh4&quot; &quot;VarIntenCh1&quot; ## [57] &quot;VarIntenCh3&quot; &quot;VarIntenCh4&quot; ## [59] &quot;WidthCh1&quot; &quot;XCentroid&quot; ## [61] &quot;YCentroid&quot; ## [1] 2019 61 Parsimony: ## Class Area Perimeter ## 1 PS 3278.726 154.89876 ## 2 WS 1727.410 84.56460 ## 3 PS 1194.932 101.09107 ## 4 WS 1027.222 68.71062 ## 5 PS 1035.608 73.40559 ## 6 PS 1433.918 79.47569 The dataset is already split between training and test sets, all that is to be added is cross-validation on the training set. set.seed(2222) folds &lt;- vfold_cv(train, v = 10) A first visualization of the relationship between the two predictors. Check for Class imbalance of the response variable This would be the first level transformation of the response, this type of transformation is considered a structural transformation, we will see more about it later in the book. PS WS tb_class 636.00 373.00 pr_class 0.63 0.37 up_samp_ws &lt;- pr_class[2] Recipes library(themis) log_rec_natural_units &lt;- recipe(Class ~ Area + Perimeter, data = train) %&gt;% step_upsample(Class, over_ratio = up_samp_ws) log_rec_inverse_units &lt;- recipe(Class ~ Area + Perimeter, data = train) %&gt;% step_upsample(Class, over_ratio = up_samp_ws) %&gt;% step_BoxCox(all_numeric()) Workflow logistic_reg_glm_spec &lt;- logistic_reg() %&gt;% set_engine(&#39;glm&#39;) log_wfl_natural_units &lt;- workflow() %&gt;% add_model(logistic_reg_glm_spec) %&gt;% add_recipe(log_rec_natural_units) log_fit_natural_units &lt;- log_wfl_natural_units %&gt;% fit(train) log_fit_natural_units %&gt;% extract_fit_parsnip() %&gt;% tidy() # A tibble: 3 × 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 1.58 0.248 6.36 1.99e-10 2 Area 0.00301 0.000281 10.7 8.95e-27 3 Perimeter -0.0682 0.00604 -11.3 1.47e-29 Prediction with_pred_natural_units &lt;- log_fit_natural_units %&gt;% augment(test) with_pred_natural_units %&gt;% head # A tibble: 6 × 6 Class Area Perimeter .pred_class .pred_PS .pred_WS &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; 1 PS 742. 68.8 PS 0.705 0.295 2 PS 1140. 86.5 PS 0.707 0.293 3 WS 692. 49.5 WS 0.429 0.571 4 WS 709. 50.4 WS 0.431 0.569 5 PS 1006. 89.9 PS 0.820 0.180 6 WS 1983. 112. PS 0.516 0.484 Confusion Matrics Roc Curve with_pred_natural_units %&gt;% roc_curve(Class,.pred_PS) %&gt;% mutate(Format = &quot;Natural Units&quot;) %&gt;% ggplot(aes(1 - specificity, sensitivity))+ geom_line(aes(color = .threshold), size = 1)+ geom_abline(linetype = &quot;dashed&quot;, size = 1, color = &quot;gray&quot;) + scale_colour_continuous()+ theme_fivethirtyeight() + theme(axis.title = element_text()) Workflow set Let’s compare the two transformations with a workflow_set(): full_workflow &lt;- workflow_set( models = list(logitstic = logistic_reg_glm_spec), preproc = list(natural_units = log_rec_natural_units, inverse_units = log_rec_inverse_units)) system.time( grid_results &lt;- full_workflow %&gt;% workflow_map( seed = 1503, resamples = folds, grid = 25, control = control_grid( save_pred = TRUE, parallel_over = &quot;everything&quot;, save_workflow = TRUE), verbose = TRUE) ) user system elapsed 9.928 0.044 9.974 grid_results # A workflow set/tibble: 2 × 4 wflow_id info option result &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; 1 natural_units_logitstic &lt;tibble [1 × 4]&gt; &lt;opts[3]&gt; &lt;rsmp[+]&gt; 2 inverse_units_logitstic &lt;tibble [1 × 4]&gt; &lt;opts[3]&gt; &lt;rsmp[+]&gt; Roc curves for two different recipes roc &lt;- grid_results %&gt;% unnest(result) %&gt;% unnest(.predictions) %&gt;% select(wflow_id, .pred_PS, .pred_WS, .pred_class, Class) %&gt;% group_by(wflow_id) %&gt;% roc_curve(Class, .pred_PS) roc_curves &lt;- roc %&gt;% ggplot( aes(x = 1 - specificity, y = sensitivity, group = wflow_id, color = wflow_id) ) + geom_line(size = 0.5) + geom_abline(lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 0.8)+ scale_color_tableau()+ theme_fivethirtyeight()+ theme(axis.title = element_text()) roc_curves "],["important-concepts.html", "1.4 Important concepts", " 1.4 Important concepts Overfitting Supervised and unsupervised Model bias and variance Experience and empirically driven modeling Generalizing the main boundaries, the risk of overfitting the model is always challenged by anomalous patterns new data can hide. 1.4.1 Acknowledge vulnerabilities To consider: small number of observations compared to the number of predictors low bias models can have a higher likelihood of overfitting supervised analysis can be used to detect predictors significance No free lunch therem (Wolpert, 1996) - knowledge is an important part of modeling variance-bias trade-off Low variance: linear/logistic regression and PLS High variance: trees, nearest neighbor, neural networks Bias: level of ability to closer estimation irrilevant predictors can causing excess model variation be data-driven rather than experience-driven big data does not mean better data unlabeled data can improve autoencoders modeling compensatory effect there may not be a unique set of predictors. Finally, one more important consideration is to consider Strategies for Supervised and Unsupervised feature selections. Supervised selection method can be divided into: wrapper methods, such as backwards and stepwise selection embedded methods, such as decision tree variable selection Unsupervised selection method variable encoding, such as dummy or indicator variables 1.4.2 The Modeling process Few steps summary: EDA summary and correlation model methods evaluation model tuning summary measures and EDA residual analysis/ check for systematic issues more feature engineering model selection final bake off prediction "],["predicting-ridership-on-chicago.html", "1.5 Predicting ridership on Chicago", " 1.5 Predicting ridership on Chicago This set will be widely used in the book to predict the number of people entering a train station daily. library(modeldata) modeldata::Chicago %&gt;% head ## # A tibble: 6 × 50 ## rider…¹ Austin Quinc…² Belmont Arche…³ Oak_P…⁴ Western Clark…⁵ Clinton Merch…⁶ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 15.7 1.46 8.37 4.60 2.01 1.42 3.32 15.6 2.40 6.48 ## 2 15.8 1.50 8.35 4.72 2.09 1.43 3.34 15.7 2.40 6.48 ## 3 15.9 1.52 8.36 4.68 2.11 1.49 3.36 15.6 2.37 6.40 ## 4 15.9 1.49 7.85 4.77 2.17 1.44 3.36 15.7 2.42 6.49 ## 5 15.4 1.50 7.62 4.72 2.06 1.42 3.27 15.6 2.42 5.80 ## 6 2.42 0.693 0.911 2.27 0.624 0.426 1.11 2.41 0.814 0.858 ## # … with 40 more variables: Irving_Park &lt;dbl&gt;, Washington_Wells &lt;dbl&gt;, ## # Harlem &lt;dbl&gt;, Monroe &lt;dbl&gt;, Polk &lt;dbl&gt;, Ashland &lt;dbl&gt;, Kedzie &lt;dbl&gt;, ## # Addison &lt;dbl&gt;, Jefferson_Park &lt;dbl&gt;, Montrose &lt;dbl&gt;, California &lt;dbl&gt;, ## # temp_min &lt;dbl&gt;, temp &lt;dbl&gt;, temp_max &lt;dbl&gt;, temp_change &lt;dbl&gt;, dew &lt;dbl&gt;, ## # humidity &lt;dbl&gt;, pressure &lt;dbl&gt;, pressure_change &lt;dbl&gt;, wind &lt;dbl&gt;, ## # wind_max &lt;dbl&gt;, gust &lt;dbl&gt;, gust_max &lt;dbl&gt;, percip &lt;dbl&gt;, percip_max &lt;dbl&gt;, ## # weather_rain &lt;dbl&gt;, weather_snow &lt;dbl&gt;, weather_cloud &lt;dbl&gt;, … 1.5.1 Extra Resources Cooking Your Data with Recipes Here is a nice example on how to Compute a sliding mean by Julia Silge caret-vs-tidymodels tidymodels-or-caret-how-they-compare "],["meeting-videos.html", "1.6 Meeting Videos", " 1.6 Meeting Videos 1.6.1 Cohort 1 Meeting chat log LOG "],["illustrative-example-predicting-risk-of-ischemic-stroke.html", "Chapter 2 Illustrative Example: Predicting Risk of Ischemic Stroke", " Chapter 2 Illustrative Example: Predicting Risk of Ischemic Stroke Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1.html", "2.1 SLIDE 1", " 2.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-1.html", "2.2 Meeting Videos", " 2.2 Meeting Videos 2.2.1 Cohort 1 Meeting chat log LOG "],["a-review-of-the-predictive-modeling-process.html", "Chapter 3 A Review of the Predictive Modeling Process", " Chapter 3 A Review of the Predictive Modeling Process Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-1.html", "3.1 SLIDE 1", " 3.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-2.html", "3.2 Meeting Videos", " 3.2 Meeting Videos 3.2.1 Cohort 1 Meeting chat log LOG "],["exploratory-visualizations.html", "Chapter 4 Exploratory Visualizations", " Chapter 4 Exploratory Visualizations Learning objectives: Perform exploratory data visualization for the Chicago train ridership and OKCupid datasets. Perform univariate and bivariate visualizations for numerical variables. Perform visualizations for categorical variables. Perform post-modeling visualizations. "],["data-visualization-chart.html", "4.1 Data Visualization Chart", " 4.1 Data Visualization Chart Source: Exploratory Data Analysis for Feature Selection in Machine Learning - Google Cloud Another reference for data visualization using R Data Visualization with R "],["introduction-to-the-chicago-train-ridership-dataset.html", "4.2 Introduction to the Chicago Train Ridership Dataset", " 4.2 Introduction to the Chicago Train Ridership Dataset Source: Wikimedia Commons, Creative Commons license Our interest is predicting the ridership at the Clark/Lake in the Chicago Loop. Source: Google Maps "],["chicago-train-ridership-dataset.html", "4.3 Chicago Train Ridership dataset", " 4.3 Chicago Train Ridership dataset library(tidyverse) library(lubridate) library(plotly) library(patchwork) library(here) ## here() starts at /home/runner/work/bookclub-feat_eng/bookclub-feat_eng library(heatmaply) ## Loading required package: viridis ## Loading required package: viridisLite ## ## Attaching package: &#39;viridis&#39; ## The following object is masked from &#39;package:scales&#39;: ## ## viridis_pal ## ## ====================== ## Welcome to heatmaply version 1.3.0 ## ## Type citation(&#39;heatmaply&#39;) for how to cite the package. ## Type ?heatmaply for the main documentation. ## ## The github page is: https://github.com/talgalili/heatmaply/ ## Please submit your suggestions and bug-reports at: https://github.com/talgalili/heatmaply/issues ## You may ask questions at stackoverflow, use the r and heatmaply tags: ## https://stackoverflow.com/questions/tagged/heatmaply ## ====================== library(RColorBrewer) library(skimr) library(vcd) ## Loading required package: grid library(colorspace) library(FactoMineR) library(caret) load(url(&quot;https://github.com/topepo/FES/blob/master/Data_Sets/Chicago_trains/chicago.RData?raw=true&quot;)) load(url(&quot;https://github.com/topepo/FES/blob/master/Data_Sets/Chicago_trains/stations.RData?raw=true&quot;)) Create train_plot_data train_plot_data &lt;- training %&gt;% mutate(date = train_days) %&gt;% relocate(date, .before = everything()) train_plot_data ## # A tibble: 5,698 × 1,092 ## date s_40380 dow doy week month year Advent1st Advent2nd Advent…¹ ## &lt;date&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001-01-22 15.7 Mon 22 4 Jan 2001 0 0 0 ## 2 2001-01-23 15.8 Tue 23 4 Jan 2001 0 0 0 ## 3 2001-01-24 15.9 Wed 24 4 Jan 2001 0 0 0 ## 4 2001-01-25 15.9 Thu 25 4 Jan 2001 0 0 0 ## 5 2001-01-26 15.4 Fri 26 4 Jan 2001 0 0 0 ## 6 2001-01-27 2.42 Sat 27 4 Jan 2001 0 0 0 ## 7 2001-01-28 1.47 Sun 28 4 Jan 2001 0 0 0 ## 8 2001-01-29 15.5 Mon 29 5 Jan 2001 0 0 0 ## 9 2001-01-30 15.9 Tue 30 5 Jan 2001 0 0 0 ## 10 2001-01-31 15.9 Wed 31 5 Jan 2001 0 0 0 ## # … with 5,688 more rows, 1,082 more variables: Advent4th &lt;dbl&gt;, ## # AllSaints &lt;dbl&gt;, AllSouls &lt;dbl&gt;, Annunciation &lt;dbl&gt;, Ascension &lt;dbl&gt;, ## # AshWednesday &lt;dbl&gt;, AssumptionOfMary &lt;dbl&gt;, BirthOfVirginMary &lt;dbl&gt;, ## # BoxingDay &lt;dbl&gt;, CaRemembranceDay &lt;dbl&gt;, CelebrationOfHolyCross &lt;dbl&gt;, ## # ChristmasEve &lt;dbl&gt;, ChristTheKing &lt;dbl&gt;, CorpusChristi &lt;dbl&gt;, Easter &lt;dbl&gt;, ## # EasterMonday &lt;dbl&gt;, EasterSunday &lt;dbl&gt;, Epiphany &lt;dbl&gt;, ## # MassOfArchangels &lt;dbl&gt;, PalmSunday &lt;dbl&gt;, Pentecost &lt;dbl&gt;, … "],["preliminary-exploratory-visualizations.html", "4.4 Preliminary exploratory visualizations", " 4.4 Preliminary exploratory visualizations Ridership line plot by month g1 &lt;- train_plot_data %&gt;% select(date, rides = s_40380) %&gt;% mutate(date = floor_date(date, &quot;month&quot;)) %&gt;% arrange(date) %&gt;% group_by(date) %&gt;% summarise(rides = sum(rides), .groups = &#39;drop&#39;) %&gt;% ggplot(aes(date, rides)) + geom_line(size = 1) + geom_smooth(method = &#39;loess&#39;, se = FALSE, color = &#39;steelblue&#39;) + scale_x_date(date_labels = &quot;%b-%Y&quot;, date_breaks =&quot;2 year&quot;)+ labs(x = &#39;&#39;, y = &quot;Rides (000&#39;s)&quot;, title = &#39;Chicago Clark/Lake Train Station Monthly Ridership Volume (Jan 2001 - Aug 2016)&#39; ) + theme(axis.text.x = element_text(angle = 60, hjust = 1)) ggplotly(g1) ## `geom_smooth()` using formula &#39;y ~ x&#39; Boxplot rides by day of the week g2 &lt;- train_plot_data %&gt;% select(dow, rides = s_40380) %&gt;% ggplot(aes(dow, rides, fill = dow)) + geom_boxplot() + labs(x = &#39;&#39;, y = &quot;Rides (000&#39;s)&quot;, title = &#39;Chicago Clark/Lake Train Station Ridership by Day of the Week&#39;) + theme(legend.position = &#39;none&#39;) ggplotly(g2) Violinplot rides by day of the week train_plot_data %&gt;% select(dow, rides = s_40380) %&gt;% ggplot(aes(dow, rides, fill = dow)) + geom_violin() + labs(x = &#39;&#39;, y = &quot;Rides (000&#39;s)&quot;, title = &#39;Chicago Clark/Lake Train Station Ridership by Day of the Week&#39;) + theme(legend.position = &#39;none&#39;) Boxplot rides by month g3 &lt;- train_plot_data %&gt;% select(month, rides = s_40380) %&gt;% ggplot(aes(month, rides, fill = month)) + geom_boxplot() + labs(x = &#39;&#39;, y = &quot;Rides (000&#39;s)&quot;, title = &#39;Chicago Clark/Lake Train Monthly Station Ridership&#39;) + theme(legend.position = &#39;none&#39;) ggplotly(g3) "],["visualizations-for-numeric-data.html", "4.5 Visualizations for Numeric Data", " 4.5 Visualizations for Numeric Data 4.5.1 Box Plots, Violin Plots, and Histograms Understanding the distribution of the response g4 &lt;- train_plot_data %&gt;% ggplot(aes(x = &quot;&quot;, y = s_40380)) + geom_boxplot(fill = &quot;blue&quot;, alpha = 0.5) + ylab(&quot;Clark/Lake Rides (x1000)&quot;) + theme( axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank() ) + coord_flip() + ylim(-2, 29) ggplotly(g4) y_hist &lt;- ggplot(train_plot_data, aes(s_40380)) + geom_histogram(binwidth = .7, col = &quot;#D53E4F&quot;, fill = &quot;#D53E4F&quot;, alpha = .5) + xlab(&quot;Clark/Lake Rides (x1000)&quot;) + ylab(&quot;Frequency&quot;) + ggtitle(&quot;(a)&quot;) + xlim(-2,29) + theme( axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank() ) y_box &lt;- ggplot(train_plot_data, aes(x = &quot;&quot;, y = s_40380)) + geom_boxplot(alpha = 0.2) + ylab(&quot;Clark/Lake Rides (x1000)&quot;) + ggtitle(&quot;(b)&quot;) + theme( axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank() ) + coord_flip() + ylim(-2,29) y_violin &lt;- ggplot(train_plot_data, aes(x = &quot;&quot;, y = s_40380)) + geom_violin(alpha = 0.2) + ylab(&quot;Clark/Lake Rides (x1000)&quot;) + ggtitle(&quot;(c)&quot;) + theme( axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank() ) + coord_flip() + ylim(-2,29) y_hist / y_box / y_violin ## Warning: Removed 2 rows containing missing values (geom_bar). The histogram (a) allows us to see that there are two peaks or modes in ridership distribution indicating that there may be two mechanisms affecting ridership. The box plot (b) does not have the ability to see multiple peaks in the data. However the violin plot (c) provides a compact visualization that identifies the distributional nuance. 4.5.2 Augmenting Visualizations through Faceting, Colors, and Shapes Distribution of daily ridership at the Clark/Lake stop from 2001 to 2016 colored and faceted by weekday and weekend. l10_breaks &lt;- scales::trans_breaks(&quot;log10&quot;, function(x) 10^x) l10_labels &lt;- scales::trans_format(&quot;log10&quot;, scales::math_format(10^.x)) all_pred %&gt;% mutate(pow = as.factor(ifelse(dow %in% c(&quot;Sat&quot;,&quot;Sun&quot;), &quot;Weekend&quot;, &quot;Weekday&quot;))) %&gt;% ggplot(aes(s_40380 * 1000, fill = pow, col = pow)) + facet_wrap( ~ pow, nrow = 2, scales = &quot;free_y&quot;) + geom_histogram(binwidth = .03, alpha = .5) + scale_fill_manual(values = c(&quot;#D53E4F&quot;, &quot;#3ed5c4&quot;)) + scale_color_manual(values = c(&quot;#D53E4F&quot;, &quot;#3ed5c4&quot;)) + scale_x_log10(breaks = l10_breaks, labels = l10_labels) + xlab(&quot;Clark/Lakes Rides&quot;) + ylab(&quot;Frequency&quot;) + theme(legend.position=&quot;none&quot;) 4.5.3 Scatterplots Scatterplots are numeric-to-numeric visualizations. Example: A scatter plot of the 14-day lag ridership at the Clark/Lake station and the current-day ridership at the same station. # create &#39;pow&#39; (weekend/weekday flag) train_plot_data &lt;- train_plot_data %&gt;% mutate( pow = ifelse(dow %in% c(&quot;Sat&quot;, &quot;Sun&quot;), &quot;Weekend&quot;, &quot;Weekday&quot;), pow = factor(pow) ) train_plot_data %&gt;% select(l14_40380, s_40380, pow) %&gt;% ggplot(aes(l14_40380,s_40380, col = pow)) + geom_point(alpha=0.5) + scale_color_manual(values = c(&quot;#D53E4F&quot;, &quot;#3ed5c4&quot;)) + xlab(&quot;Two-week Lag in Ridership (x1000)&quot;) + ylab(&quot;Current Day Ridership (x1000)&quot;) + theme(legend.title=element_blank()) + coord_equal() In general, there is a strong linear relationship between the 14-day lag and current-day ridership. However, there are many 14-day lag/current day pairs of days that lie far off from the overall scatter of points. 4.5.4 Scatterplots - Exclude U.S. holidays Let’s filter major U.S. holidays from the train_plot_data. commonHolidays &lt;- c(&quot;USNewYearsDay&quot;, &quot;Jan02_Mon_Fri&quot;, &quot;USMLKingsBirthday&quot;, &quot;USPresidentsDay&quot;, &quot;USMemorialDay&quot;, &quot;USIndependenceDay&quot;, &quot;Jul03_Mon_Fri&quot;, &quot;Jul05_Mon_Fri&quot;, &quot;USLaborDay&quot;, &quot;USThanksgivingDay&quot;, &quot;Day_after_Thx&quot;, &quot;ChristmasEve&quot;, &quot;USChristmasDay&quot;, &quot;Dec26_wkday&quot;, &quot;Dec31_Mon_Fri&quot;) any_holiday &lt;- train_plot_data %&gt;% dplyr::select(date, !!commonHolidays) %&gt;% gather(holiday, value, -date) %&gt;% group_by(date) %&gt;% summarize(common_holiday = max(value)) %&gt;% ungroup() %&gt;% mutate(common_holiday = ifelse(common_holiday == 1, &quot;Holiday&quot;, &quot;Non-holiday&quot;)) %&gt;% inner_join(train_plot_data, by = &quot;date&quot;) holiday_values &lt;- any_holiday %&gt;% dplyr::select(date, common_holiday) make_lag &lt;- function(x, lag = 14) { x$date &lt;- x$date + days(lag) prefix &lt;- ifelse(lag &lt; 10, paste0(&quot;0&quot;, lag), lag) prefix &lt;- paste0(&quot;l&quot;, prefix, &quot;_holiday&quot;) names(x) &lt;- gsub(&quot;common_holiday&quot;, prefix, names(x)) x } lag_hol &lt;- make_lag(holiday_values, lag = 14) holiday_data &lt;- any_holiday %&gt;% left_join(lag_hol, by = &quot;date&quot;) %&gt;% mutate( year = factor(year), l14_holiday = ifelse(is.na(l14_holiday), &quot;Non-holiday&quot;, l14_holiday) ) no_holiday_plot &lt;- holiday_data %&gt;% dplyr::filter(common_holiday == &quot;Non-holiday&quot; &amp; l14_holiday == &quot;Non-holiday&quot;) %&gt;% ggplot(aes(l14_40380, s_40380, col = pow)) + geom_point(alpha=0.5) + scale_color_manual(values = c(&quot;#D53E4F&quot;, &quot;#3ed5c4&quot;)) + xlab(&quot;14-Day Lag&quot;) + ylab(&quot;Current Day&quot;) + theme(legend.title=element_blank())+ coord_equal() no_holiday_plot Filtering the holidays, the weekday scatterplot compactness improves (less outliers scattered on both sides of the cluster). 4.5.5 Heatmaps For the ridership data, we will create a month and day predictor, a year predictor, and an indicator of weekday ridership less than 10,000 rides. heatmap_data &lt;- all_pred %&gt;% mutate(pow = as.factor(ifelse(dow %in% c(&quot;Sat&quot;,&quot;Sun&quot;), &quot;Weekend&quot;, &quot;Weekday&quot;))) %&gt;% dplyr::select(date, s_40380, pow) %&gt;% mutate( mmdd = format(as.Date(date), &quot;%m-%d&quot;), yyyy = format(as.Date(date), &quot;%Y&quot;), lt10 = ifelse(s_40380 &lt; 10 &amp; pow==&quot;Weekday&quot;, 1, 0) ) # U.S. holidays break_vals &lt;- c(&quot;01-01&quot;,&quot;01-15&quot;,&quot;02-01&quot;,&quot;02-15&quot;,&quot;03-01&quot;,&quot;03-15&quot;,&quot;04-01&quot;, &quot;04-15&quot;,&quot;05-01&quot;,&quot;05-15&quot;,&quot;06-01&quot;,&quot;06-15&quot;, &quot;07-01&quot;,&quot;07-15&quot;, &quot;08-01&quot;, &quot;08-15&quot;,&quot;09-01&quot;,&quot;09-15&quot;,&quot;10-01&quot;,&quot;10-15&quot;,&quot;11-01&quot;, &quot;11-15&quot;,&quot;12-01&quot;,&quot;12-15&quot;) heatmap_data %&gt;% ggplot(aes(yyyy, mmdd)) + geom_tile(aes(fill = lt10), colour = &quot;white&quot;) + scale_fill_gradient(low = &quot;transparent&quot;, high = &quot;red&quot;) + scale_y_discrete( breaks = break_vals ) + xlab(&quot;Year&quot;) + ylab(&quot;Month &amp; Day&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;) This visualization indicates that the distinct patterns of low ridership on weekdays occur on and around major US holidays. 4.5.6 Correlation Matrix Plots Visualization of the correlation matrix of the 14-day lag ridership station predictors for non-holiday, weekdays in 2016. cor_mat &lt;- holiday_data %&gt;% dplyr::filter(year == &quot;2016&quot;) %&gt;% dplyr::select(matches(&quot;l14_[0-9]&quot;), pow, common_holiday) %&gt;% dplyr::filter(pow == &quot;Weekday&quot; &amp; common_holiday == &quot;Non-holiday&quot;) %&gt;% dplyr::select(-pow, -common_holiday) %&gt;% cor() cor_map &lt;- heatmaply_cor( cor_mat, symm = TRUE, cexRow = .0001, cexCol = .0001, branches_lwd = .1 ) cor_map Ridership across stations is positively correlated (red) for nearly all pairs of stations. This means that low ridership at one station corresponds to relatively low ridership at another station, and high ridership at one station corresponds to relatively high ridership at another station. For feature selection, the high degree of correlation is a clear indicator that the information present across the stations is redundant and could be eliminated or reduced. 4.5.7 Line plots Monthly average ridership per year by weekday (excluding holidays) or weekend. year_cols &lt;- colorRampPalette(colors = brewer.pal(n = 9, &quot;YlOrRd&quot;)[-1])(16) holiday_data %&gt;% dplyr::filter(common_holiday == &quot;Non-holiday&quot;) %&gt;% dplyr::mutate(year = factor(year)) %&gt;% group_by( month = lubridate::month(date, label = TRUE, abbr = TRUE), year, pow ) %&gt;% dplyr::summarize(average_ridership = mean(s_40380, na.rm = TRUE)) %&gt;% ggplot(aes(month, average_ridership)) + facet_wrap( ~ pow, ncol = 2) + geom_line(aes(group = year, col = year), size = 1.1) + xlab(&quot;&quot;) + ylab(&quot;Geometric Mean Ridership (x1000)&quot;) + scale_color_manual(values = year_cols) + guides( col = guide_legend( title = &quot;&quot;, nrow = 2, byrow = TRUE ) ) + theme(legend.position = &quot;top&quot;) ## `summarise()` has grouped output by &#39;month&#39;, &#39;year&#39;. You can override using the ## `.groups` argument. Weekend ridership also shows annual trends but exhibits more variation within the trends for some years. The Weekend line plots have the highest variation during 2008, with much higher ridership in the summer. Monthly average gas price per gallon (USD) per year. holiday_data %&gt;% dplyr::filter(common_holiday == &quot;Non-holiday&quot;) %&gt;% mutate(year = factor(year)) %&gt;% group_by( month = lubridate::month(date, label = TRUE, abbr = TRUE), year ) %&gt;% dplyr::summarize(average_l14_gas_price = mean(l14_gas_price, na.rm = TRUE)) %&gt;% ggplot(aes(x = month, y = average_l14_gas_price)) + geom_line(aes(group = year, col = year), size = 1.3) + xlab(&quot;&quot;) + ylab(&quot;Average Gas Price/Gallon ($)&quot;) + scale_color_manual(values = year_cols) + guides( col = guide_legend( title = &quot;&quot;, nrow = 2, byrow = TRUE ) ) + theme(legend.position = &quot;top&quot;) ## `summarise()` has grouped output by &#39;month&#39;. You can override using the ## `.groups` argument. Prices spike in the summer of 2008, which is at the same time that weekend ridership spikes. 4.5.8 Principal Component Analysis (PCA) Principal component analysis of the 14-day station lag ridership. lag_14_data &lt;- holiday_data %&gt;% dplyr::select(matches(&quot;l14_[0-9]&quot;)) PCA_station &lt;- prcomp(lag_14_data) var_explained &lt;- c(0, PCA_station$sdev ^ 2) cumulative_var &lt;- cumsum(var_explained) pct_var_explained &lt;- 100 * cumulative_var / max(cumulative_var) var_df &lt;- tibble( Component = seq_along(pct_var_explained) - 1, pct_var_explained = pct_var_explained ) score_data &lt;- tibble( y = holiday_data$s_40380, year = factor(holiday_data$year), pow = holiday_data$pow, PC1 = PCA_station$x[, 1], PC2 = PCA_station$x[, 2], dow = holiday_data$dow ) pca_rng &lt;- extendrange(c(score_data$PC1, score_data$PC2)) var_plot &lt;- var_df %&gt;% dplyr::filter(Component &lt;= 50) %&gt;% ggplot(aes(x = Component, y = pct_var_explained)) + geom_line(size = 1.3) + ylim(0, 100) + xlab(&quot;Component&quot;) + ylab(&quot;Percent Variance Explained&quot;) + ggtitle(&quot;(a)&quot;) score_plot12 &lt;- ggplot(score_data, aes(PC1,PC2)) + geom_point(size = 1, alpha = 0.25) + xlab(&quot;Component 1&quot;) + ylab(&quot;Component 2&quot;) + xlim(pca_rng) + ylim(pca_rng) + ggtitle(&quot;(b)&quot;) score1_vs_day &lt;- ggplot(score_data, aes(x = dow, y = PC1)) + geom_violin(adjust = 1.5) + ylab(&quot;Component 1&quot;) + xlab(&quot;&quot;) + ylim(pca_rng) + ggtitle(&quot;(c)&quot;) score2_vs_year &lt;- ggplot(score_data, aes(x = year, y = PC2, col = year)) + geom_violin(adjust = 1.5) + ylab(&quot;Component 2&quot;) + xlab(&quot;&quot;) + # ylim(pca_rng) + scale_color_manual(values = year_cols)+ theme(legend.position = &quot;none&quot;) + ggtitle(&quot;(d)&quot;) (var_plot + score_plot12) / score1_vs_day / score2_vs_year The cumulative variability summarized across the first 10 components (a). A scatter plot of the first two principal components. The first component focuses on variation due to part of the week while the second component focuses on variation due to time (year) (b). The relationship between the first principal component and ridership for each day of the week at the Clark/Lake station (c). The relationship between second principal component and ridership for each year at the Clark/Lake station (d). "],["visualizations-for-categorical-data-exploring-the-okcupid-dataset.html", "4.6 Visualizations for Categorical Data: Exploring the OKCupid dataset", " 4.6 Visualizations for Categorical Data: Exploring the OKCupid dataset OkCupid is an online dating site that serves international users. Kim and Escobedo-Land (2015) describe a data set where over 50,000 profiles from the San Francisco area. load(url(&quot;https://github.com/topepo/FES/blob/master/Data_Sets/OkCupid/okc.RData?raw=true&quot;)) First look at the dataset # bind &#39;okc_test&#39; okc &lt;- okc_train %&gt;% bind_rows(okc_test) Skim okc skimr::skim(okc) %&gt;% knitr::kable() skim_type skim_variable n_missing complete_rate factor.ordered factor.n_unique factor.top_counts numeric.mean numeric.sd numeric.p0 numeric.p25 numeric.p50 numeric.p75 numeric.p100 numeric.hist factor diet 0 1 FALSE 19 die: 19691, mos: 15229, any: 5440, str: 4583 NA NA NA NA NA NA NA NA factor drinks 0 1 FALSE 7 soc: 36756, rar: 5328, oft: 4531, not: 2868 NA NA NA NA NA NA NA NA factor drugs 0 1 FALSE 4 nev: 32805, dru: 11758, som: 6818, oft: 366 NA NA NA NA NA NA NA NA factor education 0 1 FALSE 33 gra: 21423, gra: 8151, wor: 5193, ed_: 3572 NA NA NA NA NA NA NA NA factor income 0 1 FALSE 13 mis: 40584, inc: 2876, inc: 1572, inc: 1080 NA NA NA NA NA NA NA NA factor offspring 0 1 FALSE 16 kid: 29360, doe: 6744, doe: 3653, doe: 3322 NA NA NA NA NA NA NA NA factor pets 0 1 FALSE 16 pet: 15181, lik: 13642, lik: 6534, lik: 3988 NA NA NA NA NA NA NA NA factor religion 0 1 FALSE 10 rel: 15333, agn: 8043, oth: 7231, ath: 6316 NA NA NA NA NA NA NA NA factor sign 0 1 FALSE 13 sig: 7818, leo: 3922, gem: 3911, can: 3784 NA NA NA NA NA NA NA NA factor smokes 0 1 FALSE 6 no: 38941, smo: 3619, som: 3268, whe: 2688 NA NA NA NA NA NA NA NA factor status 0 1 FALSE 5 sin: 48032, see: 1814, ava: 1624, mar: 269 NA NA NA NA NA NA NA NA factor where_state 0 1 FALSE 36 cal: 51672, new: 15, ill: 6, mas: 4 NA NA NA NA NA NA NA NA factor where_town 0 1 FALSE 51 san: 26683, oak: 6214, ber: 3616, san: 1168 NA NA NA NA NA NA NA NA factor religion_modifer 0 1 FALSE 5 rel: 25718, but: 11469, and: 8309, and: 4221 NA NA NA NA NA NA NA NA factor sign_modifer 0 1 FALSE 4 sig: 17909, and: 17709, but: 15511, and: 618 NA NA NA NA NA NA NA NA factor Class 0 1 FALSE 2 oth: 42190, ste: 9557 NA NA NA NA NA NA NA NA numeric age 0 1 NA NA NA 3.255509e+01 9.518919e+00 18 26.000000 30.000000 37.000000 109.000000 ▇▂▁▁▁ numeric height 0 1 NA NA NA 6.833121e+01 3.979818e+00 1 66.000000 68.000000 71.000000 95.000000 ▁▁▁▇▁ numeric last_online 0 1 NA NA NA 3.916536e+01 7.625808e+01 0 1.000000 4.000000 30.000000 370.000000 ▇▁▁▁▁ numeric cpp 0 1 NA NA NA 2.898700e-03 5.376220e-02 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric cpp_fluently 0 1 NA NA NA 1.252250e-02 1.112020e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric cpp_okay 0 1 NA NA NA 9.855600e-03 9.878610e-02 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric cpp_poorly 0 1 NA NA NA 7.382100e-03 8.560210e-02 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric lisp 0 1 NA NA NA 5.991000e-04 2.446880e-02 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric lisp_fluently 0 1 NA NA NA 1.488000e-03 3.854640e-02 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric lisp_okay 0 1 NA NA NA 2.319000e-03 4.810030e-02 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric lisp_poorly 0 1 NA NA NA 2.280300e-03 4.769870e-02 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric asian 0 1 NA NA NA 1.371094e-01 3.439661e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric black 0 1 NA NA NA 5.637040e-02 2.306379e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric hispanic_latin 0 1 NA NA NA 8.937720e-02 2.852901e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric indian 0 1 NA NA NA 2.467780e-02 1.551426e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric middle_eastern 0 1 NA NA NA 1.571110e-02 1.243564e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric native_american 0 1 NA NA NA 2.125730e-02 1.442422e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric other 0 1 NA NA NA 6.083440e-02 2.390287e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric pacific_islander 0 1 NA NA NA 2.475510e-02 1.553793e-01 0 0.000000 0.000000 0.000000 1.000000 ▇▁▁▁▁ numeric white 0 1 NA NA NA 6.474578e-01 4.777663e-01 0 0.000000 1.000000 1.000000 1.000000 ▅▁▁▁▇ numeric essay_length 0 1 NA NA NA 3.132866e+00 6.777757e-01 0 3.009026 3.269513 3.480438 4.983486 ▁▁▂▇▁ numeric profile 0 1 NA NA NA 2.587400e+04 1.493822e+04 1 12937.500000 25874.000000 38810.500000 51747.000000 ▇▇▇▇▇ Plot Class okc %&gt;% ggplot(aes(Class, fill = Class)) + geom_bar() + theme(legend.position = &#39;none&#39;) 4.6.1 Visualizing Relationships between Outcomes and Predictors 4.6.1.1 Outcome and Categorical Predictor Let’s plot the frequency of the stated religion, partitioned and color by the outcome (Class). binom_stats &lt;- function(x, ...) { x &lt;- x$Class[!is.na(x$Class)] res &lt;- prop.test(x = sum(x == &quot;stem&quot;), n = length(x), ...) data.frame(Proportion = unname(res$estimate), Lower = res$conf.int[1], Upper = res$conf.int[2]) } stem_rate &lt;- mean(okc_train$Class == &quot;stem&quot;) religion_rates &lt;- okc_train %&gt;% group_by(religion) %&gt;% do(binom_stats(.)) %&gt;% arrange(Proportion) %&gt;% ungroup() %&gt;% mutate(religion = gsub(&quot;religion_&quot;, &quot;&quot;, religion), religion = reorder(factor(religion), Proportion)) okc_train &lt;- okc_train %&gt;% mutate( religion2 = gsub(&quot;religion_&quot;, &quot;&quot;, as.character(religion)), religion2 = factor(religion2, levels = as.character(religion_rates$religion)) ) bars &lt;- ggplot(okc_train, aes(x = religion2, fill = Class)) + geom_bar(position = position_dodge()) + scale_fill_brewer(palette = &quot;Paired&quot;) + xlab(&quot;&quot;) + theme(legend.position = &quot;top&quot;, axis.text = element_text(size = 8)) + ggtitle(&quot;(a)&quot;) stacked_vars &lt;- ggplot(okc_train, aes(x = religion2, fill = Class)) + geom_bar(position = &quot;fill&quot;) + scale_fill_brewer(palette = &quot;Paired&quot;) + xlab(&quot;&quot;) + ylab(&quot;Proportion&quot;) + theme(legend.position = &quot;none&quot;, axis.text = element_text(size = 8)) + ggtitle(&quot;(b)&quot;) ci_plots &lt;- ggplot(religion_rates, aes(x = religion, y = Proportion)) + geom_hline(yintercept = stem_rate, col = &quot;red&quot;, alpha = .35, lty = 2) + geom_point() + geom_errorbar(aes(ymin = Lower, ymax = Upper), width = .1) + theme(axis.text = element_text(size = 8)) + xlab(&quot;&quot;) + ggtitle(&quot;(c)&quot;) bars / stacked_vars / ci_plots Does religion appear to be related to the outcome? Since there is a gradation of rates of STEM professions between the groups, it would appear so. 4.6.1.2 Outcome and Numerical Predictor Now, let’s visualize the relationship between a categorical outcome (Class) and a numerical predictor (essay_length). l10_breaks &lt;- scales::trans_breaks(&quot;log10&quot;, function(x) 10^x) l10_labels &lt;- scales::trans_format(&quot;log10&quot;, scales::math_format(10^.x)) gam_dat &lt;- okc_train %&gt;% dplyr::select(essay_length, Class) %&gt;% arrange(essay_length) gam_small &lt;- gam_dat %&gt;% distinct(essay_length) gam_mod &lt;- mgcv::gam(Class ~ s(essay_length), data = gam_dat, family = binomial()) gam_small &lt;- gam_small %&gt;% mutate( link = -predict(gam_mod, gam_small, type = &quot;link&quot;), se = predict(gam_mod, gam_small, type = &quot;link&quot;, se.fit = TRUE)$se.fit, upper = link + qnorm(.975) * se, lower = link - qnorm(.975) * se, lower = binomial()$linkinv(lower), upper = binomial()$linkinv(upper), probability = binomial()$linkinv(link) ) brks &lt;- l10_breaks(exp(okc_train$essay_length)) essay_hist &lt;- ggplot(okc_train, aes(x = exp(essay_length))) + geom_histogram(binwidth = .1, col = &quot;#FEB24C&quot;, fill = &quot;#FED976&quot;) + facet_wrap(~ Class, ncol = 1) + scale_x_log10(breaks = brks, labels = l10_labels) + xlab(&quot;Essay Character Length&quot;) + theme_bw() + theme(plot.margin = unit(c(0,1,0,1.2), &quot;cm&quot;)) + ggtitle(&quot;(a)&quot;) essay_gam &lt;- ggplot(gam_small, aes(x = exp(essay_length))) + geom_line(aes(y = probability)) + geom_ribbon(aes(ymin = lower, ymax = upper), fill = &quot;grey&quot;, alpha = .5) + geom_hline(yintercept = stem_rate, col = &quot;red&quot;, alpha = .35, lty = 2) + scale_x_log10(breaks = brks, labels = l10_labels) + theme_bw() + xlab(&quot;&quot;) + theme(plot.margin = unit(c(0,1,0,1.2), &quot;cm&quot;))+ ggtitle(&quot;(b)&quot;) essay_hist / essay_gam The black line represents the class probability of the logistic regression model and the bands denote 95% confidence intervals around the fit. The horizontal red line indicates the baseline probability of STEM profiles from the training set. This predictor might be worth including in a model but is unlikely to show a strong effect on its own. 4.6.2 Exploring Relationships Between Categorical Predictors When considering relationships between categorical data, there are several options. Once a cross-tabulation between variables is created, mosaic plots can once again be used to understand the relationship between variables. okc_train &lt;- okc_train %&gt;% mutate( drugs = factor(as.character(drugs), levels = c(&quot;drugs_missing&quot;, &quot;never&quot;, &quot;sometimes&quot;, &quot;often&quot;)), drinks = factor(as.character(drinks), levels = c(&quot;drinks_missing&quot;, &quot;not_at_all&quot;, &quot;rarely&quot;, &quot;socially&quot;, &quot;often&quot;, &quot;very_often&quot;, &quot;desperately&quot;)) ) dd_tab &lt;- table(okc_train$drugs, okc_train$drinks, dnn = c(&quot;Drugs&quot;, &quot;Alcohol&quot;)) # Formatting for slightly better printing plot_tab &lt;- dd_tab dimnames(plot_tab)[[1]][1] &lt;- &quot;missing&quot; dimnames(plot_tab)[[2]] &lt;- gsub(&quot;_&quot;, &quot; &quot;, dimnames(plot_tab)[[2]]) dimnames(plot_tab)[[2]][1] &lt;- &quot;missing&quot; dimnames(plot_tab)[[2]][6] &lt;- &quot;often\\n&quot; dimnames(plot_tab)[[2]][6] &lt;- &quot;very often&quot; dimnames(plot_tab)[[2]][7] &lt;- &quot;\\ndesperately&quot; mosaic( t(plot_tab), highlighting = TRUE, highlighting_fill = rainbow_hcl, margins = unit(c(6, 1, 1, 8), &quot;lines&quot;), labeling = labeling_border( rot_labels = c(90, 0, 0, 0), just_labels = c(&quot;left&quot;, &quot;right&quot;, &quot;center&quot;, &quot;right&quot;), offset_varnames = unit(c(3, 1, 1, 4), &quot;lines&quot;) ), keep_aspect_ratio = FALSE ) In the cross-tabulation between alcohol and drug use, the χ2 statistic is very large (4043.8) for its degrees of freedom (18) and is associated with a very small p-value (0). This indicates that there is a strong association between these two variables. ca_obj &lt;- CA(dd_tab, graph = FALSE) ca_drugs &lt;- as.data.frame(ca_obj$row$coord) ca_drugs$label &lt;- gsub(&quot;_&quot;, &quot; &quot;, rownames(ca_drugs)) ca_drugs$Variable &lt;- &quot;Drugs&quot; ca_drinks &lt;- as.data.frame(ca_obj$col$coord) ca_drinks$label &lt;- gsub(&quot;_&quot;, &quot; &quot;, rownames(ca_drinks)) ca_drinks$Variable &lt;- &quot;Alcohol&quot; ca_rng &lt;- extendrange(c(ca_drinks$`Dim 1`, ca_drinks$`Dim 2`)) ca_x &lt;- paste0(&quot;Dimension #1 (&quot;, round(ca_obj$eig[&quot;dim 1&quot;, &quot;percentage of variance&quot;], 0), &quot;%)&quot;) ca_y &lt;- paste0(&quot;Dimension #2 (&quot;, round(ca_obj$eig[&quot;dim 2&quot;, &quot;percentage of variance&quot;], 0), &quot;%)&quot;) ca_coord &lt;- rbind(ca_drugs, ca_drinks) ca_plot &lt;- ggplot(ca_coord, aes(x = `Dim 1`, y = `Dim 2`, col = Variable)) + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + geom_text(aes(label = label)) + xlim(ca_rng) + ylim(ca_rng) + xlab(ca_x) + ylab(ca_y) + coord_equal() ca_plot ## Warning: Removed 1 rows containing missing values (geom_text). The correspondence analysis principal coordinates for the drug and alcohol data in the OkCupid data. "],["post-modeling-exploratory-visualizations.html", "4.7 Post Modeling Exploratory Visualizations", " 4.7 Post Modeling Exploratory Visualizations Multiple linear regression has a rich set of diagnostics based on model residuals that aid in understanding the model fit and in identifying relationships that may be useful to include in the model. One tool from regression diagnosis that is helpful for identifying useful predictors is the partial regression plot (Neter et al. 1996). This plot utilizes residuals from two distinct linear regression models to unearth the potential usefulness of a predictor in a model. (refer to textbook for math formulas) For the Chicago data, a rolling forecast origin scheme (Section 3.4.4) was used for resampling. Figure 4.18 "],["residual-diagnostic-plots.html", "4.8 Residual Diagnostic Plots", " 4.8 Residual Diagnostic Plots The response for the regression model is the ridership at the Clark/Lake station, and our initial model will contain the predictors of week, month and year. As we saw earlier in this chapter, the distribution has two peaks, which we found were due to the part of the week (weekday versus weekend). To investigate the importance of part of the week we then regress the base predictors on part of the week and compute the hold-out residuals from this model. We can see that including part of the week in the model further reduces the residual distribution as illustrated in the histogram labeled Base + Part of Week. Next, let’s explore the importance of the 14-day lag of ridership at the Clark/Lake station. holidays &lt;- c(&quot;USNewYearsDay&quot;, &quot;Jan02_Mon_Fri&quot;, &quot;USMLKingsBirthday&quot;, &quot;USPresidentsDay&quot;, &quot;USMemorialDay&quot;, &quot;USIndependenceDay&quot;, &quot;Jul03_Mon_Fri&quot;, &quot;Jul05_Mon_Fri&quot;, &quot;USLaborDay&quot;, &quot;USThanksgivingDay&quot;, &quot;Day_after_Thx&quot;, &quot;ChristmasEve&quot;, &quot;USChristmasDay&quot;, &quot;Dec26_wkday&quot;, &quot;Dec31_Mon_Fri&quot;) common_holiday &lt;- apply(training %&gt;% dplyr::select(one_of(holidays)), 1, function(x) ifelse(any(x == 1), 1, 0)) training &lt;- training %&gt;% mutate( holiday = common_holiday, weekday = ifelse(dow %in% c(&quot;Sat&quot;, &quot;Sun&quot;), 0, 1) ) # get_resid() get_resid &lt;- function(terms, next_term, return_mod = FALSE) { ctrl$verboseIter &lt;- FALSE ctrl$predictionBounds &lt;- c(0, NA) set.seed(4194) mod &lt;- train(s_40380 ~ ., data = training[, c(&quot;s_40380&quot;, terms)], method = &quot;lm&quot;, metric = &quot;RMSE&quot;, maximize = FALSE, trControl = ctrl) x_mod &lt;- train(as.formula(paste(next_term,&quot;~ .&quot;)), data = training[, c(terms, next_term)], method = &quot;lm&quot;, metric = &quot;RMSE&quot;, maximize = FALSE, trControl = ctrl) if(!return_mod) { out &lt;- mod$pred out$Resample &lt;- ymd(out$Resample) out$Date &lt;- train_days[out$rowIndex] out$Month &lt;- training$month[out$rowIndex] out$holiday &lt;- training$holiday[out$rowIndex] out$weekday &lt;- training$weekday[out$rowIndex] out$Residual &lt;- out$obs - out$pred out$xResidual &lt;- x_mod$pred$obs - x_mod$pred$pred } else out &lt;- mod out } # There will be a warning about the &quot;outcome only has two possible values&quot;. # This can be ignored. theme_set(theme_bw()) base_resid &lt;- get_resid(terms = c(&quot;year&quot;, &quot;month&quot;, &quot;week&quot;), next_term = &quot;weekday&quot;) %&gt;% mutate(Model = &quot;Base Model&quot;) ## Warning in train.default(x, y, weights = w, ...): You are trying to do ## regression and your outcome only has two possible values Are you trying to do ## classification? If so, use a 2 level factor as your outcome column. pow_resid &lt;- get_resid(terms = c(&quot;year&quot;, &quot;month&quot;, &quot;week&quot;, &quot;weekday&quot;), next_term = &quot;l14_40380&quot;) %&gt;% mutate(Model = &quot;Base + Part of Week&quot;) l14_resid &lt;- get_resid( terms = c(&quot;year&quot;, &quot;month&quot;, &quot;week&quot;, &quot;weekday&quot;, &quot;l14_40380&quot;), next_term = &quot;holiday&quot; ) %&gt;% mutate(Model = &quot;Base + Part of Week + 14-Day Lag&quot;) ## Warning in train.default(x, y, weights = w, ...): You are trying to do ## regression and your outcome only has two possible values Are you trying to do ## classification? If so, use a 2 level factor as your outcome column. ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. hol_resid &lt;- get_resid(terms = c(&quot;year&quot;, &quot;month&quot;, &quot;week&quot;, &quot;weekday&quot;, &quot;l14_40380&quot;, &quot;holiday&quot;), next_term = &quot;l14_40370&quot;) %&gt;% mutate(Model = &quot;Base + Part of Week + 14-Day Lag + Holiday&quot;) mod_lev &lt;- c(&quot;Base Model&quot;, &quot;Base + Part of Week&quot;, &quot;Base + Part of Week + 14-Day Lag&quot;, &quot;Base + Part of Week + 14-Day Lag + Holiday&quot;) model_resid &lt;- bind_rows(base_resid, pow_resid, l14_resid, hol_resid) %&gt;% mutate( Model = factor(Model, levels = mod_lev), holiday = ifelse(holiday == 1, &quot;yes&quot;, &quot;no&quot;), weekday = ifelse(weekday == 0, &quot;Weekend&quot;, &quot;Weekday&quot;) ) resid_hists &lt;- ggplot(model_resid, aes(x = Residual)) + geom_vline(xintercept = 0, lty = 2, col = &quot;darkgreen&quot;) + geom_histogram(binwidth = 0.5, col = rgb(1, 1, 1, 0), fill = &quot;blue&quot;, alpha = .5) + facet_wrap(~Model, ncol = 1) + xlab(&quot;Resampling Residual&quot;) + ylab(&quot;Count&quot;) + ggtitle(&quot;(a)&quot;) day_resid &lt;- base_resid %&gt;% mutate(weekday = ifelse(weekday == 0, &quot;Weekend&quot;, &quot;Weekday&quot;)) %&gt;% ggplot(aes(x = xResidual, y = Residual)) + geom_smooth(se = FALSE, method = lm, col = &quot;black&quot;) + geom_point(aes(col = weekday, shape = weekday), alpha = .5) + xlab(&quot;POW Model Residuals&quot;) + ylab(&quot;Base Model \\n Residuals \\n&quot;) + theme( legend.position = c(.2, .8), legend.background = element_blank(), legend.title = element_blank() ) + ggtitle(&quot;(b)&quot;) l14_PR_resid &lt;- ggplot(pow_resid, aes(x = xResidual, y = Residual)) + geom_point(alpha = .5) + xlab(&quot;14-day Lag Model Residuals&quot;) + ylab(&quot;Base + POW Model \\n Residuals \\n&quot;) + ggtitle(&quot;(c)&quot;) hol_PR_resid &lt;- l14_resid %&gt;% mutate(holiday = ifelse(holiday == 1, &quot;yes&quot;, &quot;no&quot;)) %&gt;% ggplot(aes(x = xResidual, y = Residual)) + geom_smooth(se = FALSE, method = lm, col = &quot;black&quot;) + geom_point(aes(col = holiday, shape = holiday), alpha = .5) + xlab(&quot;Holiday Model Residuals&quot;) + ylab(&quot;Base + POW + \\n 14-day Lag Model \\n Residuals&quot;) + theme( legend.position = c(.2, .25), legend.background = element_blank(), legend.title = element_blank() ) + ggtitle(&quot;(d)&quot;) resid_hists | (day_resid / l14_PR_resid / hol_PR_resid) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## `geom_smooth()` using formula &#39;y ~ x&#39; The distribution of residuals from the model resampling process for the base model and the base model plus other potentially useful predictors for explaining ridership at the Clark/Lake station. (a) The partial regression plot for the effect of part of the week. (b) The partial regression plot for the 14-day lag predictor of the Clark/Lake station. (c) The partial regression plot for holiday classification. (d) "],["meeting-videos-3.html", "4.9 Meeting Videos", " 4.9 Meeting Videos 4.9.1 Cohort 1 Meeting chat log LOG "],["encoding-categorical-predictors.html", "Chapter 5 Encoding Categorical Predictors", " Chapter 5 Encoding Categorical Predictors Categorical (also called nominal) predictors are those that contain qualitative data. Examples include: Education level ZIP code Text Day of the week Color A large majority of models require that all predictors be numeric. A summary of parsnip model preprocessors from: Tidy Modeling with R by Max Kuhn and Julia Silge knitr::opts_chunk$set(fig.path = &quot;images/&quot;) suppressPackageStartupMessages({ library(tidyverse) library(tidymodels) library(embed) library(cli) library(kableExtra) }) Table 5.1: Preprocessing methods for different models. model dummy zv impute decorrelate normalize transform bag_mars() ✔ × ✔ ◌ × ◌ bag_tree() × × × ◌¹ × × bart() × × × ◌¹ × × boost_tree() ×² ◌ ✔² ◌¹ × × C5_rules() × × × × × × cubist_rules() × × × × × × decision_tree() × × × ◌¹ × × discrim_flexible() ✔ × ✔ ✔ × ◌ discrim_linear() ✔ ✔ ✔ ✔ × ◌ discrim_regularized() ✔ ✔ ✔ ✔ × ◌ gen_additive_mod() ✔ ✔ ✔ ✔ × ◌ linear_reg() ✔ ✔ ✔ ✔ × ◌ logistic_reg() ✔ ✔ ✔ ✔ × ◌ mars() ✔ × ✔ ◌ × ◌ mlp() ✔ ✔ ✔ ✔ ✔ ✔ multinom_reg() ✔ ✔ ✔ ✔ ×² ◌ naive_Bayes() × ✔ ✔ ◌¹ × × nearest_neighbor() ✔ ✔ ✔ ◌ ✔ ✔ pls() ✔ ✔ ✔ × ✔ ✔ poisson_reg() ✔ ✔ ✔ ✔ × ◌ rand_forest() × ◌ ✔² ◌¹ × × rule_fit() ✔ × ✔ ◌¹ ✔ × svm_*() ✔ ✔ ✔ ✔ ✔ ✔ In the table, ✔ indicates that the method is required for the model and × indicates that it is not. The ◌ symbol means that the model may be helped by the technique but it is not required. Algorithms for tree-based models naturally handle splitting both numeric and categorical predictors. These algorithms employ a series if/then statements that sequentially split the data into groups. A naive Bayes model will create a cross-tabulation between a categorical predictor and the outcome class. We will return to this point in the final section of this chapter. Simple categorical variables can also be classified as ordered or unordered. "],["creating-dummy-variables-for-unordered-categories.html", "5.1 Creating Dummy Variables for Unordered Categories", " 5.1 Creating Dummy Variables for Unordered Categories There are many methods for doing this and, to illustrate, consider a simple example for the day of the week. If we take the seven possible values and convert them into binary dummy variables, the mathematical function required to make the translation is often referred to as a contrast. These six numeric predictors would take the place of the original categorical variable. Why only six? if the values of the six dummy variables are known, then the seventh can be directly inferred. When the model has an intercept, an additional initial column of ones for all rows is included. Estimating the parameters for a linear model (as well as other similar models) involve inverting the matrix. If the model includes an intercept and contains dummy variables for all seven days, then the seven day columns would add up (row-wise) to the intercept and this linear combination would prevent the matrix inverse from being computed (as it is singular). Less than full rank encodings are sometimes called “one-hot” encodings. Generating the full set of indicator variables may be advantageous for some models that are insensitive to linear dependencies (an example: glmnet) What is the interpretation of the dummy variables? Consider a linear model for the Chicago transit data that only uses the day of the week. Using the training set to fit the model, the intercept value estimates the mean of the reference cell, which is the average number of Sunday riders in the training set, estimated to be 3.84K people. The second model parameter, for Monday, is estimated to be 12.61K. In the reference cell model, the dummy variables represent the mean value above and beyond the reference cell mean. In this case, estimate indicates that there were 12.61K more riders on Monday than Sunday. train_df &lt;- tibble(m = month.abb, number = seq(1,12, by = 1)) recipe(number ~ m, data = train_df) |&gt; step_dummy(all_nominal_predictors(), one_hot = FALSE) |&gt; prep() |&gt; bake(new_data = NULL, all_predictors()) |&gt; kable( caption = &quot;Preprocessing without One HOT (the default) contrasts with April&quot; ) |&gt; row_spec(row = 4, background = &quot;orange&quot;) |&gt; kable_styling(&quot;striped&quot;, full_width = FALSE) |&gt; scroll_box(width = &quot;800px&quot;) (#tab:chapter 5 one hot dummies)Preprocessing without One HOT (the default) contrasts with April m_Aug m_Dec m_Feb m_Jan m_Jul m_Jun m_Mar m_May m_Nov m_Oct m_Sep 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 recipe(number ~ m, data = train_df) |&gt; step_dummy(all_nominal_predictors(), one_hot = TRUE) |&gt; prep() |&gt; bake(new_data = NULL, all_predictors()) |&gt; kable( caption = &quot;Preprocessing with One HOT.&quot; ) |&gt; kable_styling(&quot;striped&quot;, full_width = FALSE) |&gt; scroll_box(width = &quot;800px&quot;) (#tab:chapter 5 one hot dummies)Preprocessing with One HOT. m_Apr m_Aug m_Dec m_Feb m_Jan m_Jul m_Jun m_Mar m_May m_Nov m_Oct m_Sep 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 "],["encoding-predictors-for-many-categories.html", "5.2 Encoding Predictors for Many Categories", " 5.2 Encoding Predictors for Many Categories What happens when the number of factor levels gets very large? For example, there are more than 40K possible ZIP codes and, depending on how the data are collected, this might produce an overabundance of dummy variables for the size of the data available. Also, ZIP codes in highly populated areas may have a higher rate of occurrence in the data, leading to a “long tail” of locations that are infrequently observed. Also, resampling will exclude some of the rarer categories from the analysis set. The first way to handle this issue is to create the full set of dummy variables and simply remove the zero and low-variance predictors. Still, we may not desire to filter these out. Another approach is to feature engineer an “other” category that pools the rarely occurring categories, assuming that such a pooling is sensible. Another way to combine categories is to use a hashing function that maps each factor level key to a hash value. The number of possible hashes is set by the user and, for numerical purposes, is a power of 2. Some computationally interesting aspects to hash functions are The only data required is the value being hashed and the resulting number of hashes. The translation process is completely deterministic. Hash functions are unidirectional; once the hash values are created, there is no way of knowing the original values. If there are a known and finite set of original values, a table can be created to do the translation but, otherwise, the keys are indeterminable when only the hash value is known. There is no free lunch when using this procedure; some of the original categories will be mapped to the same hash value (called a “collision”). The number of collisions will be largely determined by the number of features that are produced. Categories involved in collisions are not related in any meaningful way. Because of the arbitrary nature of the collisions, it is possible to have different categories whose true underlying effect are counter to one another. This might have the effect of negating the impact of the hashed feature. Hashing functions have no notion of the probability that each key will occur. As such, it is conceivable that a category that occurs with great frequency is aliased with one that is rare. In this case, the more abundant value will have a much larger influence on the effect of that hashing feature. "],["approaches-for-novel-categories.html", "5.3 Approaches for Novel Categories", " 5.3 Approaches for Novel Categories Suppose that a model is built to predict the probability that an individual works in a STEM profession and that this model depends on city names. The model will be able to predict the probability of STEM profession if a new individual lives in one of the cities in the training set. But what happens to the model prediction when a new individual lives in a city that is not represented? One strategy would be to use the previously mentioned “other” category to capture new values. This approach can also be used with feature hashing. "],["supervised-encoding-methods.html", "5.4 Supervised Encoding Methods", " 5.4 Supervised Encoding Methods Beyond dummies, there are many other ways to craft one or more numerical features from a set of nominal predictors. They include 5.4.1 Likelihood Encoding In essence, the effect of the factor level on the outcome is measured and this effect is used as new numeric features. For example, for the Ames housing data, we might calculate the mean or median sale price of a house for each neighborhood from the training data and use this statistic to represent the factor level in the model. For classification problems, a simple logistic regression model can be used to measure the effect between the categorical outcome and the categorical predictor. If the outcome event occurs with rate \\[ p \\], the odds of that event is defined as \\[ p / ( 1 − p) \\]. This is an example of a single generalized linear model applied to the hair color feature, which woudl otherwise have 12 dummy levels. as_tibble(dplyr::starwars) |&gt; count(hair_color) ## # A tibble: 13 × 2 ## hair_color n ## &lt;chr&gt; &lt;int&gt; ## 1 auburn 1 ## 2 auburn, grey 1 ## 3 auburn, white 1 ## 4 black 13 ## 5 blond 3 ## 6 blonde 1 ## 7 brown 18 ## 8 brown, grey 1 ## 9 grey 1 ## 10 none 37 ## 11 unknown 1 ## 12 white 4 ## 13 &lt;NA&gt; 5 recipe(skin_color ~ hair_color + eye_color + mass, data = as_tibble(dplyr::starwars)) |&gt; embed::step_lencode_glm(hair_color, outcome = &quot;skin_color&quot;) |&gt; prep() |&gt; bake(new_data = NULL) |&gt; slice_sample(n = 10) |&gt; kable( caption = &quot;Starwars Characters hair_color GLM embedding&quot; ) |&gt; kable_styling(&quot;striped&quot;, full_width = FALSE) (#tab:chapter 5 glm numeric embeddings)Starwars Characters hair_color GLM embedding hair_color eye_color mass skin_color -2.862201 red 113 green -21.566069 yellow 55 fair, green, yellow -21.566069 blue 89 fair -21.566069 brown 79 tan -21.566069 brown 84 light -2.862201 black NA white, blue -21.566069 brown NA tan -21.566069 blue NA fair -2.862201 red 140 metal -21.566069 brown NA light While very fast, this method has drawbacks. For example, what happens when a factor level has a single value? Theoretically, the log-odds should be infinite in the appropriate direction but, numerically, it is usually capped at a large (and inaccurate) value. One way around this issue is to use some type of shrinkage method. For example, the overall log-odds can be determined and, if the quality of the data within a factor level is poor, then this level’s effect estimate can be biased towards an overall estimate that disregards the levels of the predictor. A common method for shrinking parameter estimates is Bayesian analysis. (one doubt – step_lencode_bayes appears to only work with two class outcomes ???) as_tibble(datasets::Titanic) |&gt; count(Class) recipe(Survived ~ Class + Sex + Age, data = as_tibble(datasets::Titanic)) |&gt; embed::step_lencode_bayes(Class, outcome = &quot;Survived&quot;) |&gt; prep() |&gt; bake(new_data = NULL) |&gt; slice_sample(n = 10) # A tibble: 10 × 4 Class Sex Age Survived &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; 1 -0.0108 Female Adult Yes 2 -0.0108 Male Adult No 3 -0.00526 Male Child Yes 4 -0.00526 Female Child No 5 -0.00993 Male Adult No 6 -0.0104 Male Child Yes 7 -0.00526 Male Child No 8 -0.0108 Female Adult No 9 -0.00993 Male Child Yes 10 -0.0104 Female Child No Empirical Bayes methods can also be used, in the form of linear (and generalized linear) mixed models. One issue with effect encoding, independent of the estimation method, is that it increases the possibility of overfitting the training data. Use resampling. Another supervised approach comes from the deep learning literature on the analysis of textual data. In addition to the dimension reduction, there is the possibility that these methods can estimate semantic relationships between words so that words with similar themes (e.g., “dog”, “pet”, etc.) have similar values in the new encodings. This technique is not limited to text data and can be used to encode any type of qualitative variable. An example using The Office dialogue and one of the pre-trained GloVe embeddings. library(textrecipes) library(schrute) glove6b &lt;- textdata::embedding_glove6b(dimensions = 100) # the download is 822.2 Mb schrute::theoffice |&gt; slice_sample(n = 10) |&gt; select(character, text) recipe(character ~ text, data = schrute::theoffice) |&gt; step_tokenize(text, options = list(strip_punct = TRUE)) |&gt; step_stem(text) |&gt; step_word_embeddings(text, embeddings = glove6b) |&gt; prep() |&gt; bake(new_data = schrute::theoffice |&gt; slice_sample(n = 10)) The Office dialogue word embeddings with glove6b # A tibble: 10 × 101 character wordembe…¹ worde…² worde…³ worde…⁴ worde…⁵ worde…⁶ &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Angela -1.02 -0.377 0.797 -1.21 -0.802 0.656 2 Roy 0 0 0 0 0 0 3 Phyllis -1.20 -0.373 3.20 -1.60 -1.62 -0.160 4 Kevin -1.54 1.77 5.02 -4.68 -5.23 2.91 5 Roy -2.15 0.735 4.07 -2.20 -1.30 0.297 6 Jim -0.595 0.419 0.699 -0.328 -1.20 1.70 7 Kelly -2.17 4.38 5.97 -4.91 -4.21 4.13 8 Katy -0.891 -0.889 0.0937 -0.859 1.42 1.49 9 Kevin -0.0308 0.120 0.539 -0.437 -0.739 -0.153 10 Jim -0.395 0.240 1.14 -1.27 -1.47 1.39 # … with 94 more variables: wordembed_text_d7 &lt;dbl&gt;, # wordembed_text_d8 &lt;dbl&gt;, wordembed_text_d9 &lt;dbl&gt;, # wordembed_text_d10 &lt;dbl&gt;, wordembed_text_d11 &lt;dbl&gt;, # wordembed_text_d12 &lt;dbl&gt;, wordembed_text_d13 &lt;dbl&gt;, # wordembed_text_d14 &lt;dbl&gt;, wordembed_text_d15 &lt;dbl&gt;, # wordembed_text_d16 &lt;dbl&gt;, wordembed_text_d17 &lt;dbl&gt;, # wordembed_text_d18 &lt;dbl&gt;, wordembed_text_d19 &lt;dbl&gt;, … Note that in place of thousands of sparse dummy colums for each tokenized word, the training set consists of 100 numeric feature dimensions. See also Textrecipes series: Pretrained Word Embedding by Emil Hvitfeldt "],["encodings-for-ordered-data.html", "5.5 Encodings for Ordered Data", " 5.5 Encodings for Ordered Data Suppose that the factors have a relative ordering, like low, medium, and high. R uses a technique called polynomial contrasts to numerically characterize the relationships. values &lt;- c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;) dat &lt;- data.frame(x = ordered(values, levels = values)) # https://bookdown.org/max/FES/encodings-for-ordered-data.html#tab:categorical-ordered-table model.matrix(~ x, dat) ## (Intercept) x.L x.Q ## 1 1 -7.071068e-01 0.4082483 ## 2 1 -7.850462e-17 -0.8164966 ## 3 1 7.071068e-01 0.4082483 ## attr(,&quot;assign&quot;) ## [1] 0 1 1 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$x ## [1] &quot;contr.poly&quot; # using recipes ---------------------------------------------------------------- # https://bookdown.org/max/FES/encodings-for-ordered-data.html#tab:categorical-ordered-table recipe(~ x, data = dat) |&gt; step_dummy(x) |&gt; prep() |&gt; bake(new_data = NULL) ## # A tibble: 3 × 2 ## x_1 x_2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -7.07e- 1 0.408 ## 2 -7.85e-17 -0.816 ## 3 7.07e- 1 0.408 It is important to recognize that patterns described by polynomial contrasts may not effectively relate a predictor to the response. For example, in some cases, one might expect a trend where “low” and “middle” samples have a roughly equivalent response but “high” samples have a much different response. In this case, polynomial contrasts are unlikely to be effective at modeling this trend. Other alternatives to polynomial contrasts: Leave the predictors as unordered factors. Translate the ordered categories into a single set of numeric scores based on context-specific information. Simple visualizations and context-specific expertise can be used to understand whether either of these approaches are good ideas. "],["creating-features-for-text-data.html", "5.6 Creating Features for Text Data", " 5.6 Creating Features for Text Data Often, data contain textual fields that are gathered from questionnaires, articles, reviews, tweets, and other sources. Are there words or phrases that would make good predictors of the outcome? To determine this, the text data must first be processed and cleaned. One approach is to measure for “importance”, that is, keywords with odds-ratios of at least 2 (in either direction) to be considered for modeling. See also Supervised Machine Learning for Text Analysis in R for a much better explanation. Other methods for preprocessing text data include: removing commonly used stop words, such as “is”, “the”, “and”, etc. stemming the words so that similar words, such as the singular and plural versions, are represented as a single entity. filter for the most common tokens, and then calculate the term frequency-inverse document frequency (tf-idf) statistic for each token "],["factors-versus-dummy-variables-in-tree-based-models.html", "5.7 Factors versus Dummy Variables in Tree-Based Models", " 5.7 Factors versus Dummy Variables in Tree-Based Models Certain types of models have the ability to use categorical data in its natural form. For example, a Chicago ridership decision tree could split on if day in {Sun, Sat} then ridership = 4.4K else ridership = 17.3K Suppose the day of the week had been converted to dummy variables. What would have occurred? In this case, the model is slightly more complex since it can only create rules as a function of a single dummy variable at a time: if day = Sun then ridership = 3.84K else if day = Sat then ridership = 4.96K else ridership = 17.30K So, for decision trees and naiive bayes does it matter how the categorical features are encoded? To answer this question, a series of experiments was conducted. The results: For these data sets, there is no real difference in the area under the ROC curve between the encoding methods. In terms of performance, it appears that differences between the two encodings are rare (but can occur). One other statistic was computed for each of the simulations: the time to train the models. Here, there is very strong trend that factor-based models are more efficiently trained than their dummy variable counterparts. One other effect of how qualitative predictors are encoded is related to summary measures. Many of these techniques, especially tree-based models, calculate variable importance scores that are relative measures for how much a predictor affected the outcome. For example, trees measure the effect of a specific split on the improvement in model performance (e.g., impurity, residual error, etc.). As predictors are used in splits, these improvements are aggregated; these can be used as the importance scores. "],["summary.html", "5.8 Summary", " 5.8 Summary With the exception of tree-based models, categorical predictors must first be converted to numeric representations to enable other models to use the information. The simplest feature engineering technique is to convert each category to a separate binary dummy predictor. Some models require one fewer dummy predictors than the number of categories. Creating dummy predictors may not be the most effective way. If, for instance, the predictor has ordered categories, then polynomial contrasts may be better. Text fields, too, can be viewed as an agglomeration of categorical predictors and must be converted to numerics. "],["meeting-videos-4.html", "5.9 Meeting Videos", " 5.9 Meeting Videos 5.9.1 Cohort 1 No chat for this session LOG "],["engineering-numeric-predictors.html", "Chapter 6 Engineering Numeric Predictors", " Chapter 6 Engineering Numeric Predictors Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-2.html", "6.1 SLIDE 1", " 6.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-5.html", "6.2 Meeting Videos", " 6.2 Meeting Videos 6.2.1 Cohort 1 Meeting chat log LOG "],["detecting-interaction-effects.html", "Chapter 7 Detecting Interaction Effects", " Chapter 7 Detecting Interaction Effects Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-3.html", "7.1 SLIDE 1", " 7.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-6.html", "7.2 Meeting Videos", " 7.2 Meeting Videos 7.2.1 Cohort 1 Meeting chat log LOG "],["handling-missing-data.html", "Chapter 8 Handling Missing Data", " Chapter 8 Handling Missing Data Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-4.html", "8.1 SLIDE 1", " 8.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-7.html", "8.2 Meeting Videos", " 8.2 Meeting Videos 8.2.1 Cohort 1 Meeting chat log LOG "],["working-with-profile-data.html", "Chapter 9 Working with Profile Data", " Chapter 9 Working with Profile Data Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-5.html", "9.1 SLIDE 1", " 9.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-8.html", "9.2 Meeting Videos", " 9.2 Meeting Videos 9.2.1 Cohort 1 Meeting chat log LOG "],["feature-selection-overview.html", "Chapter 10 Feature Selection Overview", " Chapter 10 Feature Selection Overview Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-6.html", "10.1 SLIDE 1", " 10.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-9.html", "10.2 Meeting Videos", " 10.2 Meeting Videos 10.2.1 Cohort 1 Meeting chat log LOG "],["greedy-search-methods.html", "Chapter 11 Greedy Search Methods", " Chapter 11 Greedy Search Methods Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-7.html", "11.1 SLIDE 1", " 11.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-10.html", "11.2 Meeting Videos", " 11.2 Meeting Videos 11.2.1 Cohort 1 Meeting chat log LOG "],["global-search-methods.html", "Chapter 12 Global Search Methods", " Chapter 12 Global Search Methods Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-8.html", "12.1 SLIDE 1", " 12.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-11.html", "12.2 Meeting Videos", " 12.2 Meeting Videos 12.2.1 Cohort 1 Meeting chat log LOG "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
